{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.utils as utils\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import Compose, Normalize, Resize, ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_PATH = 'output'\n",
    "IMAGE_SIZE = 64    # 图像尺寸，原图是28*28的，缩放为64*64\n",
    "BATCH_SIZE = 32\n",
    "IMAGE_CHANNEL = 1  # 输出图像通道数\n",
    "Z_DIM = 100\n",
    "G_HIDDEN = 64\n",
    "X_DIM = 64\n",
    "D_HIDDEN = 64\n",
    "EPOCH_NUM = 10\n",
    "REAL_LABEL = 1.0\n",
    "FAKE_LABEL = 0.0\n",
    "lr = 2e-4\n",
    "seed = np.random.randint(1, 10000)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = torch.tensor(0.5)\n",
    "std = torch.tensor(0.5)\n",
    "\n",
    "compose = Compose([Resize(IMAGE_SIZE, antialias=True) ,ToTensor(), Normalize(mean,std)])\n",
    "train_dataset = datasets.MNIST('./data', train=True, transform=compose)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    \"\"\"默认参数是按均匀分布随机初始化的\n",
    "       为了加速收敛，重新按正态分布初始化\n",
    "    \"\"\"\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"\"\" 合成网络将一个z_dim@1*1图像反向卷积为1@64*64的图像\n",
    "    \"\"\"\n",
    "    def __init__(self, z_dim=Z_DIM, g_hidden=G_HIDDEN, \n",
    "                 image_channel=IMAGE_CHANNEL) -> None:\n",
    "        super().__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.g_hidden = g_hidden\n",
    "        self.image_channel = image_channel\n",
    "        self.cnn1 = nn.ConvTranspose2d(in_channels=self.z_dim, out_channels=\n",
    "            self.g_hidden*8, kernel_size=4, stride=1, padding=0, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=self.g_hidden*8)\n",
    "        self.cnn2 = nn.ConvTranspose2d(in_channels=self.g_hidden*8, out_channels=\n",
    "            self.g_hidden*4, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=self.g_hidden*4)\n",
    "        self.cnn3 = nn.ConvTranspose2d(in_channels=self.g_hidden*4, out_channels=\n",
    "            self.g_hidden*2, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=self.g_hidden*2)\n",
    "        self.cnn4 = nn.ConvTranspose2d(in_channels=self.g_hidden*2, out_channels=\n",
    "            self.g_hidden, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn4 = nn.BatchNorm2d(num_features=self.g_hidden)\n",
    "        self.cnn5 = nn.ConvTranspose2d(in_channels=self.g_hidden, out_channels=\n",
    "            self.image_channel,kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # 输入：100@1*1\n",
    "        X = self.cnn1(X)\n",
    "        X = self.bn1(X)\n",
    "        X = F.relu(X, inplace=True)\n",
    "        # 输入：512@4*4\n",
    "        X = self.cnn2(X)\n",
    "        X = self.bn2(X)\n",
    "        X = F.relu(X, inplace=True)\n",
    "        # 输入：256@8*8\n",
    "        X = self.cnn3(X)\n",
    "        X = self.bn3(X)\n",
    "        X = F.relu(X, inplace=True)\n",
    "        # 输入：128@16*16\n",
    "        X = self.cnn4(X)\n",
    "        X = self.bn4(X)\n",
    "        X = F.relu(X, inplace=True)\n",
    "        # 输入：64@32*32\n",
    "        X = self.cnn5(X)\n",
    "        X = F.tanh(X)\n",
    "        # 输出：1@64*64\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \"\"\" 鉴别网络是一个分类网络，但是没有线性层\n",
    "        通过卷积将输入1@64*64变换为1@1*1\n",
    "    \"\"\"\n",
    "    def __init__(self, d_hidden=D_HIDDEN, image_channel=IMAGE_CHANNEL) -> None:\n",
    "        super().__init__()\n",
    "        self.image_channel = image_channel\n",
    "        self.d_hidden = d_hidden\n",
    "\n",
    "        self.cnn1 = nn.Conv2d(in_channels=self.image_channel, out_channels=\n",
    "            self.d_hidden, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.cnn2 = nn.Conv2d(in_channels=self.d_hidden, out_channels=\n",
    "            self.d_hidden*2, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=self.d_hidden*2)\n",
    "        self.cnn3 = nn.Conv2d(in_channels=self.d_hidden*2, out_channels=\n",
    "            self.d_hidden*4, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=self.d_hidden*4)\n",
    "        self.cnn4 = nn.Conv2d(in_channels=self.d_hidden*4, out_channels=\n",
    "            self.d_hidden*8, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn4 = nn.BatchNorm2d(num_features=self.d_hidden*8)\n",
    "        self.cnn5 = nn.Conv2d(in_channels=self.d_hidden*8, out_channels=1,\n",
    "            kernel_size=4, stride=1, padding=0, bias=False)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # 1@64*64\n",
    "        X = self.cnn1(X)\n",
    "        X = F.leaky_relu(X, 0.2, inplace=True)\n",
    "        # 64@32*32\n",
    "        X = self.cnn2(X)\n",
    "        X = self.bn2(X)\n",
    "        X = F.leaky_relu(X, 0.2, inplace=True)\n",
    "        # 128@16*16\n",
    "        X = self.cnn3(X)\n",
    "        X = self.bn3(X)\n",
    "        X = F.leaky_relu(X, 0.2, inplace=True)\n",
    "        # 256@8*8\n",
    "        X = self.cnn4(X)\n",
    "        X = self.bn4(X)\n",
    "        X = F.leaky_relu(X, 0.2, inplace=True)\n",
    "        # 512@4*4\n",
    "        X = self.cnn5(X)\n",
    "        # 1@1*1\n",
    "        X = F.sigmoid(X)\n",
    "        return X.view(-1, 1).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 [0/1875] loss_D_real: 0.4249 loss_D_fake: 2.2305 loss_G: 4.1628\n",
      "Epoch 0 [100/1875] loss_D_real: 0.0035 loss_D_fake: 0.0000 loss_G: 35.9233\n",
      "Epoch 0 [200/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 32.7708\n",
      "Epoch 0 [300/1875] loss_D_real: 0.0837 loss_D_fake: 0.0826 loss_G: 3.6350\n",
      "Epoch 0 [400/1875] loss_D_real: 0.4872 loss_D_fake: 1.4829 loss_G: 1.1189\n",
      "Epoch 0 [500/1875] loss_D_real: 0.1178 loss_D_fake: 0.3017 loss_G: 2.7871\n",
      "Epoch 0 [600/1875] loss_D_real: 0.2025 loss_D_fake: 2.0822 loss_G: 2.2472\n",
      "Epoch 0 [700/1875] loss_D_real: 0.0632 loss_D_fake: 0.2960 loss_G: 3.9163\n",
      "Epoch 0 [800/1875] loss_D_real: 0.3542 loss_D_fake: 0.1704 loss_G: 1.4281\n",
      "Epoch 0 [900/1875] loss_D_real: 0.2597 loss_D_fake: 0.2582 loss_G: 2.2741\n",
      "Epoch 0 [1000/1875] loss_D_real: 0.0264 loss_D_fake: 0.3098 loss_G: 3.7667\n",
      "Epoch 0 [1100/1875] loss_D_real: 0.6787 loss_D_fake: 0.3531 loss_G: 1.2375\n",
      "Epoch 0 [1200/1875] loss_D_real: 1.5760 loss_D_fake: 0.2798 loss_G: 0.3846\n",
      "Epoch 0 [1300/1875] loss_D_real: 0.0651 loss_D_fake: 0.1888 loss_G: 3.0312\n",
      "Epoch 0 [1400/1875] loss_D_real: 0.2133 loss_D_fake: 0.2550 loss_G: 2.2902\n",
      "Epoch 0 [1500/1875] loss_D_real: 0.4564 loss_D_fake: 0.8393 loss_G: 1.3722\n",
      "Epoch 0 [1600/1875] loss_D_real: 0.2066 loss_D_fake: 0.3683 loss_G: 2.2195\n",
      "Epoch 0 [1700/1875] loss_D_real: 0.2059 loss_D_fake: 0.2194 loss_G: 2.5802\n",
      "Epoch 0 [1800/1875] loss_D_real: 0.2683 loss_D_fake: 0.1134 loss_G: 2.1414\n",
      "Epoch 1 [0/1875] loss_D_real: 0.7022 loss_D_fake: 0.1765 loss_G: 0.7083\n",
      "Epoch 1 [100/1875] loss_D_real: 0.0083 loss_D_fake: 0.1098 loss_G: 5.5236\n",
      "Epoch 1 [200/1875] loss_D_real: 0.1696 loss_D_fake: 0.1298 loss_G: 3.1647\n",
      "Epoch 1 [300/1875] loss_D_real: 0.0588 loss_D_fake: 0.0083 loss_G: 5.4036\n",
      "Epoch 1 [400/1875] loss_D_real: 0.1046 loss_D_fake: 1.7205 loss_G: 4.1612\n",
      "Epoch 1 [500/1875] loss_D_real: 0.0083 loss_D_fake: 0.0537 loss_G: 4.5356\n",
      "Epoch 1 [600/1875] loss_D_real: 0.0702 loss_D_fake: 0.3734 loss_G: 4.0235\n",
      "Epoch 1 [700/1875] loss_D_real: 0.0900 loss_D_fake: 0.0275 loss_G: 4.0547\n",
      "Epoch 1 [800/1875] loss_D_real: 0.0991 loss_D_fake: 0.3577 loss_G: 3.3121\n",
      "Epoch 1 [900/1875] loss_D_real: 0.2142 loss_D_fake: 0.0701 loss_G: 2.0439\n",
      "Epoch 1 [1000/1875] loss_D_real: 0.0218 loss_D_fake: 0.4048 loss_G: 4.6676\n",
      "Epoch 1 [1100/1875] loss_D_real: 0.0102 loss_D_fake: 0.0167 loss_G: 5.5753\n",
      "Epoch 1 [1200/1875] loss_D_real: 0.0603 loss_D_fake: 0.1075 loss_G: 3.9382\n",
      "Epoch 1 [1300/1875] loss_D_real: 0.0399 loss_D_fake: 0.6196 loss_G: 2.9894\n",
      "Epoch 1 [1400/1875] loss_D_real: 0.0282 loss_D_fake: 0.0088 loss_G: 4.9462\n",
      "Epoch 1 [1500/1875] loss_D_real: 0.0205 loss_D_fake: 0.2635 loss_G: 5.0345\n",
      "Epoch 1 [1600/1875] loss_D_real: 0.7481 loss_D_fake: 0.1527 loss_G: 0.8223\n",
      "Epoch 1 [1700/1875] loss_D_real: 0.3792 loss_D_fake: 0.2470 loss_G: 1.5680\n",
      "Epoch 1 [1800/1875] loss_D_real: 0.0597 loss_D_fake: 0.2900 loss_G: 3.5444\n",
      "Epoch 2 [0/1875] loss_D_real: 0.0103 loss_D_fake: 0.0317 loss_G: 4.1700\n",
      "Epoch 2 [100/1875] loss_D_real: 0.0610 loss_D_fake: 0.3549 loss_G: 5.2224\n",
      "Epoch 2 [200/1875] loss_D_real: 0.7190 loss_D_fake: 0.0841 loss_G: 1.3429\n",
      "Epoch 2 [300/1875] loss_D_real: 0.1546 loss_D_fake: 0.0697 loss_G: 3.4482\n",
      "Epoch 2 [400/1875] loss_D_real: 0.0111 loss_D_fake: 0.0960 loss_G: 4.5576\n",
      "Epoch 2 [500/1875] loss_D_real: 0.0270 loss_D_fake: 0.0177 loss_G: 5.2962\n",
      "Epoch 2 [600/1875] loss_D_real: 1.2927 loss_D_fake: 0.3313 loss_G: 0.5199\n",
      "Epoch 2 [700/1875] loss_D_real: 0.0465 loss_D_fake: 0.1861 loss_G: 3.9623\n",
      "Epoch 2 [800/1875] loss_D_real: 0.0095 loss_D_fake: 0.0361 loss_G: 5.1162\n",
      "Epoch 2 [900/1875] loss_D_real: 0.0333 loss_D_fake: 0.8038 loss_G: 4.4747\n",
      "Epoch 2 [1000/1875] loss_D_real: 0.0142 loss_D_fake: 0.0421 loss_G: 4.5628\n",
      "Epoch 2 [1100/1875] loss_D_real: 0.0492 loss_D_fake: 0.2227 loss_G: 4.3841\n",
      "Epoch 2 [1200/1875] loss_D_real: 0.0963 loss_D_fake: 0.2016 loss_G: 3.2450\n",
      "Epoch 2 [1300/1875] loss_D_real: 0.0588 loss_D_fake: 0.0229 loss_G: 4.0757\n",
      "Epoch 2 [1400/1875] loss_D_real: 0.0293 loss_D_fake: 0.1499 loss_G: 4.2790\n",
      "Epoch 2 [1500/1875] loss_D_real: 0.0116 loss_D_fake: 0.1238 loss_G: 3.8172\n",
      "Epoch 2 [1600/1875] loss_D_real: 0.3507 loss_D_fake: 0.5868 loss_G: 1.3890\n",
      "Epoch 2 [1700/1875] loss_D_real: 0.0957 loss_D_fake: 0.1793 loss_G: 3.3307\n",
      "Epoch 2 [1800/1875] loss_D_real: 0.0136 loss_D_fake: 0.0257 loss_G: 4.5520\n",
      "Epoch 3 [0/1875] loss_D_real: 0.0380 loss_D_fake: 0.0326 loss_G: 4.1488\n",
      "Epoch 3 [100/1875] loss_D_real: 0.0017 loss_D_fake: 0.9379 loss_G: 5.6610\n",
      "Epoch 3 [200/1875] loss_D_real: 0.0131 loss_D_fake: 0.0358 loss_G: 4.5036\n",
      "Epoch 3 [300/1875] loss_D_real: 0.0779 loss_D_fake: 0.0318 loss_G: 3.8307\n",
      "Epoch 3 [400/1875] loss_D_real: 0.9995 loss_D_fake: 0.8455 loss_G: 0.7798\n",
      "Epoch 3 [500/1875] loss_D_real: 0.0036 loss_D_fake: 0.5287 loss_G: 5.5589\n",
      "Epoch 3 [600/1875] loss_D_real: 0.0345 loss_D_fake: 0.0075 loss_G: 5.2393\n",
      "Epoch 3 [700/1875] loss_D_real: 0.0087 loss_D_fake: 0.0315 loss_G: 4.9622\n",
      "Epoch 3 [800/1875] loss_D_real: 0.0037 loss_D_fake: 0.0055 loss_G: 5.9030\n",
      "Epoch 3 [900/1875] loss_D_real: 0.0661 loss_D_fake: 1.8207 loss_G: 4.0571\n",
      "Epoch 3 [1000/1875] loss_D_real: 0.1252 loss_D_fake: 0.0548 loss_G: 3.2134\n",
      "Epoch 3 [1100/1875] loss_D_real: 0.4498 loss_D_fake: 2.0654 loss_G: 5.0808\n",
      "Epoch 3 [1200/1875] loss_D_real: 0.0053 loss_D_fake: 0.1954 loss_G: 4.8055\n",
      "Epoch 3 [1300/1875] loss_D_real: 0.0045 loss_D_fake: 0.0106 loss_G: 5.5441\n",
      "Epoch 3 [1400/1875] loss_D_real: 0.1412 loss_D_fake: 0.2051 loss_G: 3.6861\n",
      "Epoch 3 [1500/1875] loss_D_real: 0.0302 loss_D_fake: 0.0496 loss_G: 4.2633\n",
      "Epoch 3 [1600/1875] loss_D_real: 0.0727 loss_D_fake: 0.0581 loss_G: 3.4090\n",
      "Epoch 3 [1700/1875] loss_D_real: 0.0039 loss_D_fake: 0.0629 loss_G: 4.3898\n",
      "Epoch 3 [1800/1875] loss_D_real: 0.0199 loss_D_fake: 0.0187 loss_G: 4.9799\n",
      "Epoch 4 [0/1875] loss_D_real: 0.0069 loss_D_fake: 0.0209 loss_G: 4.8815\n",
      "Epoch 4 [100/1875] loss_D_real: 0.0378 loss_D_fake: 0.0690 loss_G: 3.9074\n",
      "Epoch 4 [200/1875] loss_D_real: 0.4337 loss_D_fake: 0.2193 loss_G: 1.6353\n",
      "Epoch 4 [300/1875] loss_D_real: 0.2997 loss_D_fake: 0.8899 loss_G: 2.4094\n",
      "Epoch 4 [400/1875] loss_D_real: 0.0617 loss_D_fake: 0.6601 loss_G: 3.2633\n",
      "Epoch 4 [500/1875] loss_D_real: 0.0707 loss_D_fake: 1.2796 loss_G: 3.1248\n",
      "Epoch 4 [600/1875] loss_D_real: 0.0903 loss_D_fake: 0.0197 loss_G: 3.3657\n",
      "Epoch 4 [700/1875] loss_D_real: 0.0123 loss_D_fake: 0.0645 loss_G: 4.2780\n",
      "Epoch 4 [800/1875] loss_D_real: 0.3041 loss_D_fake: 0.0486 loss_G: 3.1225\n",
      "Epoch 4 [900/1875] loss_D_real: 0.0212 loss_D_fake: 0.5906 loss_G: 3.9175\n",
      "Epoch 4 [1000/1875] loss_D_real: 0.0383 loss_D_fake: 0.0109 loss_G: 4.5077\n",
      "Epoch 4 [1100/1875] loss_D_real: 0.0052 loss_D_fake: 0.3178 loss_G: 4.9654\n",
      "Epoch 4 [1200/1875] loss_D_real: 0.0891 loss_D_fake: 1.0865 loss_G: 3.9182\n",
      "Epoch 4 [1300/1875] loss_D_real: 0.0132 loss_D_fake: 0.0479 loss_G: 4.3125\n",
      "Epoch 4 [1400/1875] loss_D_real: 0.0689 loss_D_fake: 0.7458 loss_G: 3.1063\n",
      "Epoch 4 [1500/1875] loss_D_real: 0.0258 loss_D_fake: 0.0417 loss_G: 4.2072\n",
      "Epoch 4 [1600/1875] loss_D_real: 0.0693 loss_D_fake: 0.2153 loss_G: 3.5943\n",
      "Epoch 4 [1700/1875] loss_D_real: 0.0386 loss_D_fake: 0.0270 loss_G: 4.6920\n",
      "Epoch 4 [1800/1875] loss_D_real: 0.0220 loss_D_fake: 0.0052 loss_G: 5.4855\n",
      "Epoch 5 [0/1875] loss_D_real: 0.0005 loss_D_fake: 0.7707 loss_G: 9.8986\n",
      "Epoch 5 [100/1875] loss_D_real: 0.0113 loss_D_fake: 0.0105 loss_G: 5.1153\n",
      "Epoch 5 [200/1875] loss_D_real: 0.0004 loss_D_fake: 0.0056 loss_G: 5.9228\n",
      "Epoch 5 [300/1875] loss_D_real: 0.1868 loss_D_fake: 0.1886 loss_G: 3.5325\n",
      "Epoch 5 [400/1875] loss_D_real: 0.0035 loss_D_fake: 0.6546 loss_G: 6.2616\n",
      "Epoch 5 [500/1875] loss_D_real: 0.1255 loss_D_fake: 0.6404 loss_G: 5.3787\n",
      "Epoch 5 [600/1875] loss_D_real: 0.0143 loss_D_fake: 0.0811 loss_G: 4.1187\n",
      "Epoch 5 [700/1875] loss_D_real: 0.6730 loss_D_fake: 1.3735 loss_G: 0.8533\n",
      "Epoch 5 [800/1875] loss_D_real: 0.0448 loss_D_fake: 0.0323 loss_G: 4.0277\n",
      "Epoch 5 [900/1875] loss_D_real: 0.0017 loss_D_fake: 0.0168 loss_G: 5.5632\n",
      "Epoch 5 [1000/1875] loss_D_real: 0.0024 loss_D_fake: 0.0561 loss_G: 9.4201\n",
      "Epoch 5 [1100/1875] loss_D_real: 0.0001 loss_D_fake: 0.0004 loss_G: 9.6506\n",
      "Epoch 5 [1200/1875] loss_D_real: 0.0001 loss_D_fake: 0.0008 loss_G: 8.1396\n",
      "Epoch 5 [1300/1875] loss_D_real: 0.0001 loss_D_fake: 0.0017 loss_G: 7.3015\n",
      "Epoch 5 [1400/1875] loss_D_real: 0.0000 loss_D_fake: 0.0015 loss_G: 7.4032\n",
      "Epoch 5 [1500/1875] loss_D_real: 0.0000 loss_D_fake: 0.0006 loss_G: 8.2902\n",
      "Epoch 5 [1600/1875] loss_D_real: 0.0000 loss_D_fake: 0.0015 loss_G: 7.3630\n",
      "Epoch 5 [1700/1875] loss_D_real: 0.0001 loss_D_fake: 0.0004 loss_G: 8.0178\n",
      "Epoch 5 [1800/1875] loss_D_real: 0.0044 loss_D_fake: 0.0000 loss_G: 20.8940\n",
      "Epoch 6 [0/1875] loss_D_real: 0.0438 loss_D_fake: 0.0000 loss_G: 11.5971\n",
      "Epoch 6 [100/1875] loss_D_real: 0.0123 loss_D_fake: 0.0710 loss_G: 5.1102\n",
      "Epoch 6 [200/1875] loss_D_real: 0.0201 loss_D_fake: 0.0000 loss_G: 20.0127\n",
      "Epoch 6 [300/1875] loss_D_real: 0.0003 loss_D_fake: 0.0000 loss_G: 51.7322\n",
      "Epoch 6 [400/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 51.1602\n",
      "Epoch 6 [500/1875] loss_D_real: 0.0001 loss_D_fake: 0.0000 loss_G: 51.2396\n",
      "Epoch 6 [600/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 51.4265\n",
      "Epoch 6 [700/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 51.1610\n",
      "Epoch 6 [800/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 51.0201\n",
      "Epoch 6 [900/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 51.1526\n",
      "Epoch 6 [1000/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 51.2233\n",
      "Epoch 6 [1100/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 51.1721\n",
      "Epoch 6 [1200/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 51.1358\n",
      "Epoch 6 [1300/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 51.2093\n",
      "Epoch 6 [1400/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 50.8370\n",
      "Epoch 6 [1500/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 51.0686\n",
      "Epoch 6 [1600/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 51.3414\n",
      "Epoch 6 [1700/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 50.9326\n",
      "Epoch 6 [1800/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 50.9216\n",
      "Epoch 7 [0/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 50.9893\n",
      "Epoch 7 [100/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 51.0721\n",
      "Epoch 7 [200/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 51.1202\n",
      "Epoch 7 [300/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 50.7267\n",
      "Epoch 7 [400/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 50.6672\n",
      "Epoch 7 [500/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 50.9688\n",
      "Epoch 7 [600/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 50.7135\n",
      "Epoch 7 [700/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 50.9538\n",
      "Epoch 7 [800/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 50.8861\n",
      "Epoch 7 [900/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 50.5061\n",
      "Epoch 7 [1000/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 50.9419\n",
      "Epoch 7 [1100/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 50.8070\n",
      "Epoch 7 [1200/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 50.5972\n",
      "Epoch 7 [1300/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 50.3535\n",
      "Epoch 7 [1400/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 50.7482\n",
      "Epoch 7 [1500/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 50.9051\n",
      "Epoch 7 [1600/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 50.4876\n",
      "Epoch 7 [1700/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 50.6978\n",
      "Epoch 7 [1800/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 50.6812\n",
      "Epoch 8 [0/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 50.5285\n",
      "Epoch 8 [100/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 50.4073\n",
      "Epoch 8 [200/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 50.3485\n",
      "Epoch 8 [300/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 50.5602\n",
      "Epoch 8 [400/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 50.6314\n",
      "Epoch 8 [500/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 50.5181\n",
      "Epoch 8 [600/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 50.8070\n",
      "Epoch 8 [700/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 50.4607\n",
      "Epoch 8 [800/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 50.3994\n",
      "Epoch 8 [900/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 50.4168\n",
      "Epoch 8 [1000/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 50.3073\n",
      "Epoch 8 [1100/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 50.5004\n",
      "Epoch 8 [1200/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 50.3671\n",
      "Epoch 8 [1300/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 50.5854\n",
      "Epoch 8 [1400/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 50.5182\n",
      "Epoch 8 [1500/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 50.6162\n",
      "Epoch 8 [1600/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 50.5397\n",
      "Epoch 8 [1700/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 50.6829\n",
      "Epoch 8 [1800/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 50.4147\n",
      "Epoch 9 [0/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 50.3947\n",
      "Epoch 9 [100/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 50.3960\n",
      "Epoch 9 [200/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 50.3562\n",
      "Epoch 9 [300/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 50.1378\n",
      "Epoch 9 [400/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 50.3788\n",
      "Epoch 9 [500/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 50.3080\n",
      "Epoch 9 [600/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 50.0743\n",
      "Epoch 9 [700/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 50.5319\n",
      "Epoch 9 [800/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 50.0499\n",
      "Epoch 9 [900/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 50.2144\n",
      "Epoch 9 [1000/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 50.4452\n",
      "Epoch 9 [1100/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 50.2313\n",
      "Epoch 9 [1200/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 49.9760\n",
      "Epoch 9 [1300/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 50.2651\n",
      "Epoch 9 [1400/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 50.3401\n",
      "Epoch 9 [1500/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 50.1273\n",
      "Epoch 9 [1600/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 50.6909\n",
      "Epoch 9 [1700/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 50.2018\n",
      "Epoch 9 [1800/1875] loss_D_real: 0.0000 loss_D_fake: 0.0000 loss_G: 50.5198\n"
     ]
    }
   ],
   "source": [
    "netG = Generator().to(device)\n",
    "netG.apply(weights_init)\n",
    "\n",
    "netD = Discriminator().to(device)\n",
    "netD.apply(weights_init)\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "viz_noise = torch.randn(BATCH_SIZE, Z_DIM, 1, 1, device=device)\n",
    "\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "for epoch in range(EPOCH_NUM):\n",
    "    for i, (x_real, _) in enumerate(train_loader):\n",
    "        x_real = x_real.to(device)\n",
    "        real_label = torch.full((x_real.size(0),), REAL_LABEL, device=device)\n",
    "        fake_label = torch.full((x_real.size(0),), FAKE_LABEL, device=device)\n",
    "\n",
    "        # 根据真实样本更新网络D\n",
    "        netD.zero_grad()\n",
    "        y_real = netD(x_real)\n",
    "        loss_D_real = loss_fn(y_real, real_label)\n",
    "        loss_D_real.backward()\n",
    "        optimizerD.step()\n",
    "        \n",
    "        # 根据样本数据更新网络D\n",
    "        z_noise = torch.randn(x_real.size(0), Z_DIM, 1, 1, device=device)\n",
    "        x_fake = netG(z_noise).detach()\n",
    "        y_fake = netD(x_fake)\n",
    "        loss_D_fake = loss_fn(y_fake, fake_label)\n",
    "        loss_D_fake.backward()\n",
    "        optimizerD.step()\n",
    "\n",
    "        # 根据样本数据更新网络G\n",
    "        netG.zero_grad()\n",
    "        x_fake = netG(z_noise)\n",
    "        y_fake_r = netD(x_fake)\n",
    "        loss_G = loss_fn(y_fake_r, real_label)\n",
    "        loss_G.backward()\n",
    "        optimizerG.step()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f'Epoch {epoch} [{i}/{len(train_loader)}] loss_D_real: {loss_D_real.mean().item():.4f} loss_D_fake: {loss_D_fake.mean().item():.4f} loss_G: {loss_G.mean().item():.4f}')\n",
    "            \n",
    "            utils.save_image(x_real, os.path.join(OUT_PATH, f'real_samples_{epoch}.png'), normalize=True)\n",
    "            with torch.no_grad():\n",
    "                viz_sample = netG(viz_noise)\n",
    "                utils.save_image(viz_sample, os.path.join(OUT_PATH, f'fake_samples_{epoch}.png'), normalize=True)\n",
    "    torch.save(netG.state_dict(), os.path.join(OUT_PATH, f'netG_{epoch}.pth'))\n",
    "    torch.save(netD.state_dict(), os.path.join(OUT_PATH, f'netD_{epoch}.pth'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
