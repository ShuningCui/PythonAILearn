{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.utils as utils\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import Compose, Normalize, Resize, ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_PATH = 'output'\n",
    "IMAGE_SIZE = 64    # 图像尺寸，原图是28*28的，缩放为64*64\n",
    "BATCH_SIZE = 32\n",
    "IMAGE_CHANNEL = 1  # 输出图像通道数\n",
    "Z_DIM = 100\n",
    "G_HIDDEN = 64\n",
    "X_DIM = 64\n",
    "D_HIDDEN = 64\n",
    "EPOCH_NUM = 10\n",
    "REAL_LABEL = 1.0\n",
    "FAKE_LABEL = 0.0\n",
    "lr = 2e-4\n",
    "seed = np.random.randint(1, 10000)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = torch.tensor(0.5)\n",
    "std = torch.tensor(0.5)\n",
    "\n",
    "compose = Compose([Resize(IMAGE_SIZE, antialias=True) ,ToTensor(), Normalize(mean,std)])\n",
    "train_dataset = datasets.MNIST('./data', train=True, transform=compose, download=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    \"\"\"默认参数是按均匀分布随机初始化的\n",
    "       为了加速收敛，重新按正态分布初始化\n",
    "    \"\"\"\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"\"\" 合成网络将一个z_dim@1*1图像反向卷积为1@64*64的图像\n",
    "    \"\"\"\n",
    "    def __init__(self, z_dim=Z_DIM, g_hidden=G_HIDDEN, \n",
    "                 image_channel=IMAGE_CHANNEL) -> None:\n",
    "        super().__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.g_hidden = g_hidden\n",
    "        self.image_channel = image_channel\n",
    "        self.cnn1 = nn.ConvTranspose2d(in_channels=self.z_dim, out_channels=\n",
    "            self.g_hidden*8, kernel_size=4, stride=1, padding=0, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=self.g_hidden*8)\n",
    "        self.cnn2 = nn.ConvTranspose2d(in_channels=self.g_hidden*8, out_channels=\n",
    "            self.g_hidden*4, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=self.g_hidden*4)\n",
    "        self.cnn3 = nn.ConvTranspose2d(in_channels=self.g_hidden*4, out_channels=\n",
    "            self.g_hidden*2, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=self.g_hidden*2)\n",
    "        self.cnn4 = nn.ConvTranspose2d(in_channels=self.g_hidden*2, out_channels=\n",
    "            self.g_hidden, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn4 = nn.BatchNorm2d(num_features=self.g_hidden)\n",
    "        self.cnn5 = nn.ConvTranspose2d(in_channels=self.g_hidden, out_channels=\n",
    "            self.image_channel,kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # 输入：100@1*1\n",
    "        X = self.cnn1(X)\n",
    "        X = self.bn1(X)\n",
    "        X = F.relu(X, inplace=True)\n",
    "        # 输入：512@4*4\n",
    "        X = self.cnn2(X)\n",
    "        X = self.bn2(X)\n",
    "        X = F.relu(X, inplace=True)\n",
    "        # 输入：256@8*8\n",
    "        X = self.cnn3(X)\n",
    "        X = self.bn3(X)\n",
    "        X = F.relu(X, inplace=True)\n",
    "        # 输入：128@16*16\n",
    "        X = self.cnn4(X)\n",
    "        X = self.bn4(X)\n",
    "        X = F.relu(X, inplace=True)\n",
    "        # 输入：64@32*32\n",
    "        X = self.cnn5(X)\n",
    "        X = F.tanh(X)\n",
    "        # 输出：1@64*64\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \"\"\" 鉴别网络是一个分类网络，但是没有线性层\n",
    "        通过卷积将输入1@64*64变换为1@1*1\n",
    "    \"\"\"\n",
    "    def __init__(self, d_hidden=D_HIDDEN, image_channel=IMAGE_CHANNEL) -> None:\n",
    "        super().__init__()\n",
    "        self.image_channel = image_channel\n",
    "        self.d_hidden = d_hidden\n",
    "\n",
    "        self.cnn1 = nn.Conv2d(in_channels=self.image_channel, out_channels=\n",
    "            self.d_hidden, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.cnn2 = nn.Conv2d(in_channels=self.d_hidden, out_channels=\n",
    "            self.d_hidden*2, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=self.d_hidden*2)\n",
    "        self.cnn3 = nn.Conv2d(in_channels=self.d_hidden*2, out_channels=\n",
    "            self.d_hidden*4, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=self.d_hidden*4)\n",
    "        self.cnn4 = nn.Conv2d(in_channels=self.d_hidden*4, out_channels=\n",
    "            self.d_hidden*8, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn4 = nn.BatchNorm2d(num_features=self.d_hidden*8)\n",
    "        self.cnn5 = nn.Conv2d(in_channels=self.d_hidden*8, out_channels=1,\n",
    "            kernel_size=4, stride=1, padding=0, bias=False)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # 1@64*64\n",
    "        X = self.cnn1(X)\n",
    "        X = F.leaky_relu(X, 0.2, inplace=True)\n",
    "        # 64@32*32\n",
    "        X = self.cnn2(X)\n",
    "        X = self.bn2(X)\n",
    "        X = F.leaky_relu(X, 0.2, inplace=True)\n",
    "        # 128@16*16\n",
    "        X = self.cnn3(X)\n",
    "        X = self.bn3(X)\n",
    "        X = F.leaky_relu(X, 0.2, inplace=True)\n",
    "        # 256@8*8\n",
    "        X = self.cnn4(X)\n",
    "        X = self.bn4(X)\n",
    "        X = F.leaky_relu(X, 0.2, inplace=True)\n",
    "        # 512@4*4\n",
    "        X = self.cnn5(X)\n",
    "        # 1@1*1\n",
    "        X = F.sigmoid(X)\n",
    "        return X.view(-1, 1).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 [0/1875] loss_D_real: 0.2624 loss_D_fake: 1.5612 loss_G: 7.2237\n",
      "Epoch 0 [100/1875] loss_D_real: 0.0124 loss_D_fake: 0.0000 loss_G: 16.6706\n",
      "Epoch 0 [200/1875] loss_D_real: 0.0264 loss_D_fake: 0.5759 loss_G: 4.2032\n",
      "Epoch 0 [300/1875] loss_D_real: 0.1879 loss_D_fake: 0.0709 loss_G: 4.7026\n",
      "Epoch 0 [400/1875] loss_D_real: 0.1312 loss_D_fake: 0.1293 loss_G: 3.3828\n",
      "Epoch 0 [500/1875] loss_D_real: 0.1946 loss_D_fake: 0.0253 loss_G: 3.9092\n",
      "Epoch 0 [600/1875] loss_D_real: 0.0519 loss_D_fake: 0.0690 loss_G: 4.2776\n",
      "Epoch 0 [700/1875] loss_D_real: 0.3297 loss_D_fake: 0.0522 loss_G: 3.0497\n",
      "Epoch 0 [800/1875] loss_D_real: 0.1435 loss_D_fake: 0.0455 loss_G: 3.4699\n",
      "Epoch 0 [900/1875] loss_D_real: 0.0585 loss_D_fake: 1.1727 loss_G: 2.5565\n",
      "Epoch 0 [1000/1875] loss_D_real: 0.2620 loss_D_fake: 1.0710 loss_G: 6.6138\n",
      "Epoch 0 [1100/1875] loss_D_real: 0.3057 loss_D_fake: 0.0555 loss_G: 2.3494\n",
      "Epoch 0 [1200/1875] loss_D_real: 0.1161 loss_D_fake: 0.5404 loss_G: 3.2750\n",
      "Epoch 0 [1300/1875] loss_D_real: 0.0195 loss_D_fake: 0.0696 loss_G: 3.3227\n",
      "Epoch 0 [1400/1875] loss_D_real: 0.1773 loss_D_fake: 0.4520 loss_G: 4.7800\n",
      "Epoch 0 [1500/1875] loss_D_real: 0.1742 loss_D_fake: 1.2340 loss_G: 2.9479\n",
      "Epoch 0 [1600/1875] loss_D_real: 0.0869 loss_D_fake: 0.1132 loss_G: 3.0283\n",
      "Epoch 0 [1700/1875] loss_D_real: 0.0796 loss_D_fake: 0.1521 loss_G: 3.5835\n",
      "Epoch 0 [1800/1875] loss_D_real: 0.2741 loss_D_fake: 0.0296 loss_G: 3.1737\n",
      "Epoch 1 [0/1875] loss_D_real: 1.0817 loss_D_fake: 0.0082 loss_G: 2.4332\n",
      "Epoch 1 [100/1875] loss_D_real: 0.0609 loss_D_fake: 0.1128 loss_G: 4.1189\n",
      "Epoch 1 [200/1875] loss_D_real: 0.0163 loss_D_fake: 0.1060 loss_G: 5.2560\n",
      "Epoch 1 [300/1875] loss_D_real: 0.1516 loss_D_fake: 0.2732 loss_G: 3.8521\n",
      "Epoch 1 [400/1875] loss_D_real: 0.0273 loss_D_fake: 0.1025 loss_G: 4.5610\n",
      "Epoch 1 [500/1875] loss_D_real: 0.2075 loss_D_fake: 0.0635 loss_G: 3.1720\n",
      "Epoch 1 [600/1875] loss_D_real: 0.0269 loss_D_fake: 0.0356 loss_G: 4.4734\n",
      "Epoch 1 [700/1875] loss_D_real: 0.6012 loss_D_fake: 0.0158 loss_G: 2.1312\n",
      "Epoch 1 [800/1875] loss_D_real: 0.1444 loss_D_fake: 0.1467 loss_G: 2.9611\n",
      "Epoch 1 [900/1875] loss_D_real: 0.0293 loss_D_fake: 0.0513 loss_G: 4.6894\n",
      "Epoch 1 [1000/1875] loss_D_real: 0.0592 loss_D_fake: 0.4247 loss_G: 5.8007\n",
      "Epoch 1 [1100/1875] loss_D_real: 0.6029 loss_D_fake: 0.0026 loss_G: 4.1210\n",
      "Epoch 1 [1200/1875] loss_D_real: 0.0099 loss_D_fake: 0.0219 loss_G: 5.3496\n",
      "Epoch 1 [1300/1875] loss_D_real: 1.3443 loss_D_fake: 0.0039 loss_G: 1.4401\n",
      "Epoch 1 [1400/1875] loss_D_real: 0.0868 loss_D_fake: 0.0214 loss_G: 2.9359\n",
      "Epoch 1 [1500/1875] loss_D_real: 0.0762 loss_D_fake: 0.0134 loss_G: 4.7468\n",
      "Epoch 1 [1600/1875] loss_D_real: 0.0516 loss_D_fake: 0.8727 loss_G: 4.7109\n",
      "Epoch 1 [1700/1875] loss_D_real: 0.2406 loss_D_fake: 0.0396 loss_G: 2.4354\n",
      "Epoch 1 [1800/1875] loss_D_real: 0.0811 loss_D_fake: 0.3328 loss_G: 3.7492\n",
      "Epoch 2 [0/1875] loss_D_real: 0.0133 loss_D_fake: 0.0280 loss_G: 5.0725\n",
      "Epoch 2 [100/1875] loss_D_real: 0.0583 loss_D_fake: 0.0467 loss_G: 4.8349\n",
      "Epoch 2 [200/1875] loss_D_real: 0.0388 loss_D_fake: 0.0449 loss_G: 4.3194\n",
      "Epoch 2 [300/1875] loss_D_real: 0.0211 loss_D_fake: 0.0320 loss_G: 3.8567\n",
      "Epoch 2 [400/1875] loss_D_real: 0.0051 loss_D_fake: 0.0084 loss_G: 4.9995\n",
      "Epoch 2 [500/1875] loss_D_real: 0.0112 loss_D_fake: 0.9618 loss_G: 7.4550\n",
      "Epoch 2 [600/1875] loss_D_real: 0.2414 loss_D_fake: 0.0744 loss_G: 2.6568\n",
      "Epoch 2 [700/1875] loss_D_real: 0.5668 loss_D_fake: 0.0023 loss_G: 1.3345\n",
      "Epoch 2 [800/1875] loss_D_real: 0.0294 loss_D_fake: 0.0099 loss_G: 4.3491\n",
      "Epoch 2 [900/1875] loss_D_real: 0.0444 loss_D_fake: 0.3831 loss_G: 5.7940\n",
      "Epoch 2 [1000/1875] loss_D_real: 0.1528 loss_D_fake: 0.0075 loss_G: 3.0813\n",
      "Epoch 2 [1100/1875] loss_D_real: 0.3104 loss_D_fake: 0.6220 loss_G: 2.8477\n",
      "Epoch 2 [1200/1875] loss_D_real: 0.0085 loss_D_fake: 0.1781 loss_G: 5.7229\n",
      "Epoch 2 [1300/1875] loss_D_real: 0.0515 loss_D_fake: 0.1160 loss_G: 3.9282\n",
      "Epoch 2 [1400/1875] loss_D_real: 0.0258 loss_D_fake: 0.2165 loss_G: 4.6348\n",
      "Epoch 2 [1500/1875] loss_D_real: 0.0753 loss_D_fake: 0.0216 loss_G: 3.8284\n",
      "Epoch 2 [1600/1875] loss_D_real: 0.0061 loss_D_fake: 0.0104 loss_G: 5.1772\n",
      "Epoch 2 [1700/1875] loss_D_real: 0.1348 loss_D_fake: 0.0751 loss_G: 3.6620\n",
      "Epoch 2 [1800/1875] loss_D_real: 0.0220 loss_D_fake: 0.1862 loss_G: 4.2182\n",
      "Epoch 3 [0/1875] loss_D_real: 0.2279 loss_D_fake: 0.2424 loss_G: 1.8459\n",
      "Epoch 3 [100/1875] loss_D_real: 0.0330 loss_D_fake: 0.1239 loss_G: 5.3934\n",
      "Epoch 3 [200/1875] loss_D_real: 0.0244 loss_D_fake: 0.0285 loss_G: 4.9539\n",
      "Epoch 3 [300/1875] loss_D_real: 0.2499 loss_D_fake: 0.5509 loss_G: 1.9558\n",
      "Epoch 3 [400/1875] loss_D_real: 0.1324 loss_D_fake: 0.1161 loss_G: 3.5628\n",
      "Epoch 3 [500/1875] loss_D_real: 0.0249 loss_D_fake: 0.3207 loss_G: 5.6676\n",
      "Epoch 3 [600/1875] loss_D_real: 0.0719 loss_D_fake: 0.0455 loss_G: 3.8516\n",
      "Epoch 3 [700/1875] loss_D_real: 0.1090 loss_D_fake: 0.0448 loss_G: 4.2034\n",
      "Epoch 3 [800/1875] loss_D_real: 0.0090 loss_D_fake: 0.0177 loss_G: 4.5509\n",
      "Epoch 3 [900/1875] loss_D_real: 0.0081 loss_D_fake: 0.0994 loss_G: 4.7568\n",
      "Epoch 3 [1000/1875] loss_D_real: 0.3197 loss_D_fake: 0.0665 loss_G: 2.9762\n",
      "Epoch 3 [1100/1875] loss_D_real: 0.0363 loss_D_fake: 0.2509 loss_G: 5.3689\n",
      "Epoch 3 [1200/1875] loss_D_real: 0.0567 loss_D_fake: 0.0036 loss_G: 5.8180\n",
      "Epoch 3 [1300/1875] loss_D_real: 0.2824 loss_D_fake: 0.0798 loss_G: 3.3738\n",
      "Epoch 3 [1400/1875] loss_D_real: 0.0436 loss_D_fake: 0.0200 loss_G: 4.7521\n",
      "Epoch 3 [1500/1875] loss_D_real: 0.9917 loss_D_fake: 0.0009 loss_G: 1.9205\n",
      "Epoch 3 [1600/1875] loss_D_real: 0.1399 loss_D_fake: 0.0262 loss_G: 3.7636\n",
      "Epoch 3 [1700/1875] loss_D_real: 0.0074 loss_D_fake: 0.1622 loss_G: 5.6340\n",
      "Epoch 3 [1800/1875] loss_D_real: 0.0023 loss_D_fake: 0.0634 loss_G: 5.8465\n",
      "Epoch 4 [0/1875] loss_D_real: 0.0787 loss_D_fake: 1.2315 loss_G: 2.7257\n",
      "Epoch 4 [100/1875] loss_D_real: 0.0433 loss_D_fake: 0.4386 loss_G: 4.6418\n",
      "Epoch 4 [200/1875] loss_D_real: 0.0257 loss_D_fake: 1.4337 loss_G: 10.1432\n",
      "Epoch 4 [300/1875] loss_D_real: 0.0227 loss_D_fake: 0.0212 loss_G: 4.6963\n",
      "Epoch 4 [400/1875] loss_D_real: 0.0213 loss_D_fake: 0.0044 loss_G: 5.3999\n",
      "Epoch 4 [500/1875] loss_D_real: 0.1176 loss_D_fake: 0.0058 loss_G: 6.1406\n",
      "Epoch 4 [600/1875] loss_D_real: 0.1335 loss_D_fake: 0.0323 loss_G: 3.5449\n",
      "Epoch 4 [700/1875] loss_D_real: 0.0009 loss_D_fake: 0.1112 loss_G: 6.4719\n",
      "Epoch 4 [800/1875] loss_D_real: 0.0028 loss_D_fake: 0.0056 loss_G: 5.8303\n",
      "Epoch 4 [900/1875] loss_D_real: 0.4607 loss_D_fake: 0.3423 loss_G: 1.9470\n",
      "Epoch 4 [1000/1875] loss_D_real: 0.1090 loss_D_fake: 0.6536 loss_G: 5.5072\n",
      "Epoch 4 [1100/1875] loss_D_real: 0.0445 loss_D_fake: 0.0192 loss_G: 4.8152\n",
      "Epoch 4 [1200/1875] loss_D_real: 0.0198 loss_D_fake: 0.0346 loss_G: 3.4904\n",
      "Epoch 4 [1300/1875] loss_D_real: 0.0170 loss_D_fake: 0.4362 loss_G: 3.5429\n",
      "Epoch 4 [1400/1875] loss_D_real: 0.0476 loss_D_fake: 0.0766 loss_G: 4.9553\n",
      "Epoch 4 [1500/1875] loss_D_real: 0.0109 loss_D_fake: 0.1507 loss_G: 4.1411\n",
      "Epoch 4 [1600/1875] loss_D_real: 0.0141 loss_D_fake: 0.0358 loss_G: 4.3825\n",
      "Epoch 4 [1700/1875] loss_D_real: 0.0322 loss_D_fake: 0.0131 loss_G: 6.3767\n",
      "Epoch 4 [1800/1875] loss_D_real: 0.0022 loss_D_fake: 0.0072 loss_G: 5.4183\n",
      "Epoch 5 [0/1875] loss_D_real: 0.1700 loss_D_fake: 0.6423 loss_G: 4.0069\n",
      "Epoch 5 [100/1875] loss_D_real: 0.0157 loss_D_fake: 1.9676 loss_G: 5.5671\n",
      "Epoch 5 [200/1875] loss_D_real: 0.0061 loss_D_fake: 0.0939 loss_G: 5.6501\n",
      "Epoch 5 [300/1875] loss_D_real: 0.0049 loss_D_fake: 0.0145 loss_G: 5.3167\n",
      "Epoch 5 [400/1875] loss_D_real: 0.0082 loss_D_fake: 0.0101 loss_G: 5.3518\n",
      "Epoch 5 [500/1875] loss_D_real: 0.0093 loss_D_fake: 0.0282 loss_G: 4.5338\n",
      "Epoch 5 [600/1875] loss_D_real: 0.0321 loss_D_fake: 0.0141 loss_G: 4.3332\n",
      "Epoch 5 [700/1875] loss_D_real: 0.0048 loss_D_fake: 0.0125 loss_G: 5.7316\n",
      "Epoch 5 [800/1875] loss_D_real: 12.7701 loss_D_fake: 0.0000 loss_G: 1.2286\n",
      "Epoch 5 [900/1875] loss_D_real: 0.0752 loss_D_fake: 0.0322 loss_G: 3.8708\n",
      "Epoch 5 [1000/1875] loss_D_real: 0.0057 loss_D_fake: 0.0191 loss_G: 5.5008\n",
      "Epoch 5 [1100/1875] loss_D_real: 0.3175 loss_D_fake: 0.0818 loss_G: 3.2012\n",
      "Epoch 5 [1200/1875] loss_D_real: 0.0349 loss_D_fake: 0.0099 loss_G: 6.8993\n",
      "Epoch 5 [1300/1875] loss_D_real: 0.0120 loss_D_fake: 0.2129 loss_G: 5.6864\n",
      "Epoch 5 [1400/1875] loss_D_real: 0.0086 loss_D_fake: 0.1162 loss_G: 4.3001\n",
      "Epoch 5 [1500/1875] loss_D_real: 0.0123 loss_D_fake: 0.0075 loss_G: 5.1960\n",
      "Epoch 5 [1600/1875] loss_D_real: 0.3013 loss_D_fake: 0.0174 loss_G: 4.2425\n",
      "Epoch 5 [1700/1875] loss_D_real: 0.0196 loss_D_fake: 0.0082 loss_G: 5.8233\n",
      "Epoch 5 [1800/1875] loss_D_real: 0.0181 loss_D_fake: 0.0460 loss_G: 3.8765\n",
      "Epoch 6 [0/1875] loss_D_real: 0.0102 loss_D_fake: 0.0145 loss_G: 5.4048\n",
      "Epoch 6 [100/1875] loss_D_real: 0.9328 loss_D_fake: 0.2397 loss_G: 0.8121\n",
      "Epoch 6 [200/1875] loss_D_real: 0.0136 loss_D_fake: 0.0581 loss_G: 4.9245\n",
      "Epoch 6 [300/1875] loss_D_real: 0.0493 loss_D_fake: 0.0853 loss_G: 3.0797\n",
      "Epoch 6 [400/1875] loss_D_real: 0.0131 loss_D_fake: 0.0083 loss_G: 5.7595\n",
      "Epoch 6 [500/1875] loss_D_real: 0.5504 loss_D_fake: 0.1753 loss_G: 0.4770\n",
      "Epoch 6 [600/1875] loss_D_real: 0.0654 loss_D_fake: 0.0094 loss_G: 5.5166\n",
      "Epoch 6 [700/1875] loss_D_real: 0.0354 loss_D_fake: 0.6544 loss_G: 4.6786\n",
      "Epoch 6 [800/1875] loss_D_real: 0.1977 loss_D_fake: 0.0385 loss_G: 3.2953\n",
      "Epoch 6 [900/1875] loss_D_real: 0.0056 loss_D_fake: 0.0055 loss_G: 5.6982\n",
      "Epoch 6 [1000/1875] loss_D_real: 0.0030 loss_D_fake: 0.0066 loss_G: 5.7008\n",
      "Epoch 6 [1100/1875] loss_D_real: 0.0033 loss_D_fake: 0.0203 loss_G: 5.4644\n",
      "Epoch 6 [1200/1875] loss_D_real: 0.1301 loss_D_fake: 0.0183 loss_G: 4.4086\n",
      "Epoch 6 [1300/1875] loss_D_real: 0.2851 loss_D_fake: 0.8478 loss_G: 2.2084\n",
      "Epoch 6 [1400/1875] loss_D_real: 0.0138 loss_D_fake: 0.1710 loss_G: 4.0630\n",
      "Epoch 6 [1500/1875] loss_D_real: 0.0187 loss_D_fake: 0.0101 loss_G: 5.0959\n",
      "Epoch 6 [1600/1875] loss_D_real: 0.2588 loss_D_fake: 0.1692 loss_G: 1.9741\n",
      "Epoch 6 [1700/1875] loss_D_real: 0.1131 loss_D_fake: 0.0289 loss_G: 3.4955\n",
      "Epoch 6 [1800/1875] loss_D_real: 0.0058 loss_D_fake: 0.0710 loss_G: 4.8472\n",
      "Epoch 7 [0/1875] loss_D_real: 0.3896 loss_D_fake: 0.4395 loss_G: 1.8808\n",
      "Epoch 7 [100/1875] loss_D_real: 0.1005 loss_D_fake: 0.0130 loss_G: 4.3682\n",
      "Epoch 7 [200/1875] loss_D_real: 0.0215 loss_D_fake: 0.0163 loss_G: 4.4480\n",
      "Epoch 7 [300/1875] loss_D_real: 0.0121 loss_D_fake: 0.0419 loss_G: 4.4029\n",
      "Epoch 7 [400/1875] loss_D_real: 0.3670 loss_D_fake: 0.0724 loss_G: 2.1302\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuDNN error: CUDNN_STATUS_EXECUTION_FAILED",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mh:\\PythonAILearn\\chapter8\\8_8_GAN_CUDA.ipynb Cell 7\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/PythonAILearn/chapter8/8_8_GAN_CUDA.ipynb#W6sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m y_fake \u001b[39m=\u001b[39m netD(x_fake\u001b[39m.\u001b[39mdetach())\n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/PythonAILearn/chapter8/8_8_GAN_CUDA.ipynb#W6sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m loss_D_fake \u001b[39m=\u001b[39m loss_fn(y_fake, fake_label)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/h%3A/PythonAILearn/chapter8/8_8_GAN_CUDA.ipynb#W6sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m loss_D_fake\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/PythonAILearn/chapter8/8_8_GAN_CUDA.ipynb#W6sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m optimizerD\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/PythonAILearn/chapter8/8_8_GAN_CUDA.ipynb#W6sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39m# 根据样本数据更新网络G\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\cuish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    493\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    494\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\cuish\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m     tensors,\n\u001b[0;32m    253\u001b[0m     grad_tensors_,\n\u001b[0;32m    254\u001b[0m     retain_graph,\n\u001b[0;32m    255\u001b[0m     create_graph,\n\u001b[0;32m    256\u001b[0m     inputs,\n\u001b[0;32m    257\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    258\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    259\u001b[0m )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: cuDNN error: CUDNN_STATUS_EXECUTION_FAILED"
     ]
    }
   ],
   "source": [
    "netG = Generator().to(device)\n",
    "netG.apply(weights_init)\n",
    "\n",
    "netD = Discriminator().to(device)\n",
    "netD.apply(weights_init)\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "viz_noise = torch.randn(BATCH_SIZE, Z_DIM, 1, 1, device=device)\n",
    "\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "for epoch in range(EPOCH_NUM):\n",
    "    for i, (x_real, _) in enumerate(train_loader):\n",
    "        x_real = x_real.to(device)\n",
    "        real_label = torch.full((x_real.size(0),), REAL_LABEL, device=device)\n",
    "        fake_label = torch.full((x_real.size(0),), FAKE_LABEL, device=device)\n",
    "\n",
    "        # 根据真实样本更新网络D\n",
    "        netD.zero_grad()\n",
    "        y_real = netD(x_real)\n",
    "        loss_D_real = loss_fn(y_real, real_label)\n",
    "        loss_D_real.backward()\n",
    "\n",
    "        # 根据样本数据更新网络D\n",
    "        z_noise = torch.randn(x_real.size(0), Z_DIM, 1, 1, device=device)\n",
    "        x_fake = netG(z_noise)\n",
    "        y_fake = netD(x_fake.detach())\n",
    "        loss_D_fake = loss_fn(y_fake, fake_label)\n",
    "        loss_D_fake.backward()\n",
    "        optimizerD.step()\n",
    "\n",
    "        # 根据样本数据更新网络G\n",
    "        netG.zero_grad()\n",
    "        # x_fake = netG(z_noise)\n",
    "        y_fake_r = netD(x_fake)\n",
    "        loss_G = loss_fn(y_fake_r, real_label)\n",
    "        loss_G.backward()\n",
    "        optimizerG.step()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f'Epoch {epoch} [{i}/{len(train_loader)}] loss_D_real: {loss_D_real.mean().item():.4f} loss_D_fake: {loss_D_fake.mean().item():.4f} loss_G: {loss_G.mean().item():.4f}')\n",
    "            \n",
    "            utils.save_image(x_real, os.path.join(OUT_PATH, f'real_samples_{epoch}.png'), normalize=True)\n",
    "            with torch.no_grad():\n",
    "                viz_sample = netG(viz_noise)\n",
    "                utils.save_image(viz_sample, os.path.join(OUT_PATH, f'fake_samples_{epoch}.png'), normalize=True)\n",
    "    torch.save(netG.state_dict(), os.path.join(OUT_PATH, f'netG_{epoch}.pth'))\n",
    "    torch.save(netD.state_dict(), os.path.join(OUT_PATH, f'netD_{epoch}.pth'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
