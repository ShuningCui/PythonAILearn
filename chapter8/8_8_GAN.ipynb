{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.utils as utils\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import Compose, Normalize, Resize, ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x24b7d2c7bf0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OUT_PATH = 'output2'\n",
    "IMAGE_SIZE = 64    # 图像尺寸，原图是28*28的，缩放为64*64\n",
    "BATCH_SIZE = 128  \n",
    "IMAGE_CHANNEL = 1  # 输出图像通道数\n",
    "Z_DIM = 100\n",
    "G_HIDDEN = 64\n",
    "X_DIM = 64\n",
    "D_HIDDEN = 64\n",
    "EPOCH_NUM = 25\n",
    "REAL_LABEL = 1.0\n",
    "FAKE_LABEL = 0.0\n",
    "lr = 2e-4\n",
    "seed = np.random.randint(1, 10000)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = torch.tensor(0.5)\n",
    "std = torch.tensor(0.5)\n",
    "\n",
    "compose = Compose([Resize(IMAGE_SIZE, antialias=True) ,ToTensor(), Normalize(mean,std)])\n",
    "train_dataset = datasets.MNIST('./data', train=True, transform=compose, download=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    \"\"\"默认参数是按均匀分布随机初始化的\n",
    "       为了加速收敛，重新按正态分布初始化\n",
    "    \"\"\"\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"\"\" 合成网络将一个z_dim@1*1图像反向卷积为1@64*64的图像\n",
    "    \"\"\"\n",
    "    def __init__(self, z_dim=Z_DIM, g_hidden=G_HIDDEN, \n",
    "                 image_channel=IMAGE_CHANNEL) -> None:\n",
    "        super().__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.g_hidden = g_hidden\n",
    "        self.image_channel = image_channel\n",
    "        self.cnn1 = nn.ConvTranspose2d(in_channels=self.z_dim, out_channels=\n",
    "            self.g_hidden*8, kernel_size=4, stride=1, padding=0, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=self.g_hidden*8)\n",
    "        self.cnn2 = nn.ConvTranspose2d(in_channels=self.g_hidden*8, out_channels=\n",
    "            self.g_hidden*4, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=self.g_hidden*4)\n",
    "        self.cnn3 = nn.ConvTranspose2d(in_channels=self.g_hidden*4, out_channels=\n",
    "            self.g_hidden*2, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=self.g_hidden*2)\n",
    "        self.cnn4 = nn.ConvTranspose2d(in_channels=self.g_hidden*2, out_channels=\n",
    "            self.g_hidden, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn4 = nn.BatchNorm2d(num_features=self.g_hidden)\n",
    "        self.cnn5 = nn.ConvTranspose2d(in_channels=self.g_hidden, out_channels=\n",
    "            self.image_channel,kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # 输入：100@1*1\n",
    "        X = self.cnn1(X)\n",
    "        X = self.bn1(X)\n",
    "        X = F.relu(X, inplace=True)\n",
    "        # 输入：512@4*4\n",
    "        X = self.cnn2(X)\n",
    "        X = self.bn2(X)\n",
    "        X = F.relu(X, inplace=True)\n",
    "        # 输入：256@8*8\n",
    "        X = self.cnn3(X)\n",
    "        X = self.bn3(X)\n",
    "        X = F.relu(X, inplace=True)\n",
    "        # 输入：128@16*16\n",
    "        X = self.cnn4(X)\n",
    "        X = self.bn4(X)\n",
    "        X = F.relu(X, inplace=True)\n",
    "        # 输入：64@32*32\n",
    "        X = self.cnn5(X)\n",
    "        X = F.tanh(X)\n",
    "        # 输出：1@64*64\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \"\"\" 鉴别网络是一个分类网络，但是没有线性层\n",
    "        通过卷积将输入1@64*64变换为1@1*1\n",
    "    \"\"\"\n",
    "    def __init__(self, d_hidden=D_HIDDEN, image_channel=IMAGE_CHANNEL) -> None:\n",
    "        super().__init__()\n",
    "        self.image_channel = image_channel\n",
    "        self.d_hidden = d_hidden\n",
    "\n",
    "        self.cnn1 = nn.Conv2d(in_channels=self.image_channel, out_channels=\n",
    "            self.d_hidden, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.cnn2 = nn.Conv2d(in_channels=self.d_hidden, out_channels=\n",
    "            self.d_hidden*2, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=self.d_hidden*2)\n",
    "        self.cnn3 = nn.Conv2d(in_channels=self.d_hidden*2, out_channels=\n",
    "            self.d_hidden*4, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=self.d_hidden*4)\n",
    "        self.cnn4 = nn.Conv2d(in_channels=self.d_hidden*4, out_channels=\n",
    "            self.d_hidden*8, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn4 = nn.BatchNorm2d(num_features=self.d_hidden*8)\n",
    "        self.cnn5 = nn.Conv2d(in_channels=self.d_hidden*8, out_channels=1,\n",
    "            kernel_size=4, stride=1, padding=0, bias=False)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # 1@64*64\n",
    "        X = self.cnn1(X)\n",
    "        X = F.leaky_relu(X, 0.2, inplace=True)\n",
    "        # 64@32*32\n",
    "        X = self.cnn2(X)\n",
    "        X = self.bn2(X)\n",
    "        X = F.leaky_relu(X, 0.2, inplace=True)\n",
    "        # 128@16*16\n",
    "        X = self.cnn3(X)\n",
    "        X = self.bn3(X)\n",
    "        X = F.leaky_relu(X, 0.2, inplace=True)\n",
    "        # 256@8*8\n",
    "        X = self.cnn4(X)\n",
    "        X = self.bn4(X)\n",
    "        X = F.leaky_relu(X, 0.2, inplace=True)\n",
    "        # 512@4*4\n",
    "        X = self.cnn5(X)\n",
    "        # 1@1*1\n",
    "        X = F.sigmoid(X)\n",
    "        return X.view(-1, 1).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 [0/469] loss_D_real: 1.5835 loss_D_fake: 0.4194 loss_G: 1.7845\n",
      "Epoch 0 [100/469] loss_D_real: 5.4714 loss_D_fake: 0.0000 loss_G: 15.6021\n",
      "Epoch 0 [200/469] loss_D_real: 0.1042 loss_D_fake: 0.0742 loss_G: 3.4113\n",
      "Epoch 0 [300/469] loss_D_real: 0.0355 loss_D_fake: 0.0851 loss_G: 3.7141\n",
      "Epoch 0 [400/469] loss_D_real: 0.2200 loss_D_fake: 0.1684 loss_G: 2.3103\n",
      "Epoch 1 [0/469] loss_D_real: 0.0106 loss_D_fake: 0.8158 loss_G: 9.0950\n",
      "Epoch 1 [100/469] loss_D_real: 0.1053 loss_D_fake: 0.6108 loss_G: 3.6037\n",
      "Epoch 1 [200/469] loss_D_real: 0.1689 loss_D_fake: 0.4418 loss_G: 2.8731\n",
      "Epoch 1 [300/469] loss_D_real: 0.0705 loss_D_fake: 0.4724 loss_G: 3.3861\n",
      "Epoch 1 [400/469] loss_D_real: 0.6133 loss_D_fake: 0.4735 loss_G: 1.3278\n",
      "Epoch 2 [0/469] loss_D_real: 0.2913 loss_D_fake: 0.2472 loss_G: 1.8922\n",
      "Epoch 2 [100/469] loss_D_real: 0.4228 loss_D_fake: 0.0696 loss_G: 1.2518\n",
      "Epoch 2 [200/469] loss_D_real: 0.1388 loss_D_fake: 0.6160 loss_G: 2.2445\n",
      "Epoch 2 [300/469] loss_D_real: 0.0752 loss_D_fake: 0.2036 loss_G: 3.7839\n",
      "Epoch 2 [400/469] loss_D_real: 0.1653 loss_D_fake: 0.3320 loss_G: 2.6665\n",
      "Epoch 3 [0/469] loss_D_real: 0.1377 loss_D_fake: 0.0189 loss_G: 3.3132\n",
      "Epoch 3 [100/469] loss_D_real: 0.0621 loss_D_fake: 0.1976 loss_G: 3.1876\n",
      "Epoch 3 [200/469] loss_D_real: 0.1023 loss_D_fake: 0.2610 loss_G: 4.1781\n",
      "Epoch 3 [300/469] loss_D_real: 0.2955 loss_D_fake: 0.1093 loss_G: 2.6126\n",
      "Epoch 3 [400/469] loss_D_real: 0.2900 loss_D_fake: 0.3469 loss_G: 2.4941\n",
      "Epoch 4 [0/469] loss_D_real: 0.2004 loss_D_fake: 0.0725 loss_G: 3.6775\n",
      "Epoch 4 [100/469] loss_D_real: 0.2738 loss_D_fake: 0.0307 loss_G: 1.9087\n",
      "Epoch 4 [200/469] loss_D_real: 0.3147 loss_D_fake: 0.0287 loss_G: 2.1303\n",
      "Epoch 4 [300/469] loss_D_real: 0.8006 loss_D_fake: 0.0483 loss_G: 1.7513\n",
      "Epoch 4 [400/469] loss_D_real: 0.6470 loss_D_fake: 0.0372 loss_G: 0.9620\n",
      "Epoch 5 [0/469] loss_D_real: 0.1355 loss_D_fake: 0.0185 loss_G: 3.2480\n",
      "Epoch 5 [100/469] loss_D_real: 0.1760 loss_D_fake: 0.0747 loss_G: 2.6547\n",
      "Epoch 5 [200/469] loss_D_real: 0.2350 loss_D_fake: 0.0681 loss_G: 2.8475\n",
      "Epoch 5 [300/469] loss_D_real: 0.3324 loss_D_fake: 0.0942 loss_G: 2.4894\n",
      "Epoch 5 [400/469] loss_D_real: 0.0721 loss_D_fake: 0.0424 loss_G: 3.3562\n",
      "Epoch 6 [0/469] loss_D_real: 0.5707 loss_D_fake: 0.4055 loss_G: 1.3174\n",
      "Epoch 6 [100/469] loss_D_real: 0.4577 loss_D_fake: 0.3876 loss_G: 1.6991\n",
      "Epoch 6 [200/469] loss_D_real: 0.0700 loss_D_fake: 0.0287 loss_G: 4.0092\n",
      "Epoch 6 [300/469] loss_D_real: 1.0952 loss_D_fake: 0.0360 loss_G: 1.7267\n",
      "Epoch 6 [400/469] loss_D_real: 0.1600 loss_D_fake: 0.9781 loss_G: 4.9613\n",
      "Epoch 7 [0/469] loss_D_real: 0.2182 loss_D_fake: 0.2194 loss_G: 2.2248\n",
      "Epoch 7 [100/469] loss_D_real: 0.4567 loss_D_fake: 0.0539 loss_G: 2.0882\n",
      "Epoch 7 [200/469] loss_D_real: 0.3023 loss_D_fake: 0.1042 loss_G: 1.5105\n",
      "Epoch 7 [300/469] loss_D_real: 0.0287 loss_D_fake: 0.0864 loss_G: 5.1648\n",
      "Epoch 7 [400/469] loss_D_real: 0.0841 loss_D_fake: 0.1035 loss_G: 2.9442\n",
      "Epoch 8 [0/469] loss_D_real: 0.7350 loss_D_fake: 0.0290 loss_G: 1.4957\n",
      "Epoch 8 [100/469] loss_D_real: 0.0751 loss_D_fake: 0.0206 loss_G: 3.3802\n",
      "Epoch 8 [200/469] loss_D_real: 0.2020 loss_D_fake: 0.1359 loss_G: 2.2319\n",
      "Epoch 8 [300/469] loss_D_real: 1.6030 loss_D_fake: 0.0429 loss_G: 1.4872\n",
      "Epoch 8 [400/469] loss_D_real: 0.0353 loss_D_fake: 0.0301 loss_G: 4.1340\n",
      "Epoch 9 [0/469] loss_D_real: 0.5956 loss_D_fake: 0.1217 loss_G: 1.7666\n",
      "Epoch 9 [100/469] loss_D_real: 0.0865 loss_D_fake: 0.2923 loss_G: 3.2219\n",
      "Epoch 9 [200/469] loss_D_real: 0.0347 loss_D_fake: 0.0230 loss_G: 3.9308\n",
      "Epoch 9 [300/469] loss_D_real: 0.6225 loss_D_fake: 0.2214 loss_G: 0.9092\n",
      "Epoch 9 [400/469] loss_D_real: 0.1187 loss_D_fake: 0.0100 loss_G: 3.4223\n",
      "Epoch 10 [0/469] loss_D_real: 0.0263 loss_D_fake: 0.0342 loss_G: 4.2212\n",
      "Epoch 10 [100/469] loss_D_real: 0.1223 loss_D_fake: 0.5253 loss_G: 2.6135\n",
      "Epoch 10 [200/469] loss_D_real: 0.0875 loss_D_fake: 0.0461 loss_G: 2.9043\n",
      "Epoch 10 [300/469] loss_D_real: 0.1411 loss_D_fake: 0.2150 loss_G: 3.0048\n",
      "Epoch 10 [400/469] loss_D_real: 0.0711 loss_D_fake: 0.0472 loss_G: 3.3289\n",
      "Epoch 11 [0/469] loss_D_real: 0.0700 loss_D_fake: 0.0279 loss_G: 3.3078\n",
      "Epoch 11 [100/469] loss_D_real: 1.3379 loss_D_fake: 0.0013 loss_G: 0.1965\n",
      "Epoch 11 [200/469] loss_D_real: 0.1371 loss_D_fake: 0.2195 loss_G: 3.5274\n",
      "Epoch 11 [300/469] loss_D_real: 0.4058 loss_D_fake: 0.0333 loss_G: 1.5132\n",
      "Epoch 11 [400/469] loss_D_real: 0.0064 loss_D_fake: 0.4472 loss_G: 8.1462\n",
      "Epoch 12 [0/469] loss_D_real: 0.2553 loss_D_fake: 0.1100 loss_G: 2.7199\n",
      "Epoch 12 [100/469] loss_D_real: 0.0183 loss_D_fake: 0.0341 loss_G: 3.8730\n",
      "Epoch 12 [200/469] loss_D_real: 0.3389 loss_D_fake: 0.1452 loss_G: 1.8727\n",
      "Epoch 12 [300/469] loss_D_real: 0.5529 loss_D_fake: 0.0178 loss_G: 0.8945\n",
      "Epoch 12 [400/469] loss_D_real: 7.0414 loss_D_fake: 0.0001 loss_G: 1.8257\n",
      "Epoch 13 [0/469] loss_D_real: 0.3311 loss_D_fake: 0.1620 loss_G: 2.6420\n",
      "Epoch 13 [100/469] loss_D_real: 0.0176 loss_D_fake: 0.0147 loss_G: 4.6589\n",
      "Epoch 13 [200/469] loss_D_real: 0.0436 loss_D_fake: 0.1071 loss_G: 4.3926\n",
      "Epoch 13 [300/469] loss_D_real: 0.0547 loss_D_fake: 0.0347 loss_G: 3.9454\n",
      "Epoch 13 [400/469] loss_D_real: 0.2744 loss_D_fake: 0.3511 loss_G: 2.0661\n",
      "Epoch 14 [0/469] loss_D_real: 0.6472 loss_D_fake: 0.0136 loss_G: 1.6052\n",
      "Epoch 14 [100/469] loss_D_real: 0.0973 loss_D_fake: 0.0615 loss_G: 3.0897\n",
      "Epoch 14 [200/469] loss_D_real: 0.4799 loss_D_fake: 0.3044 loss_G: 1.4540\n",
      "Epoch 14 [300/469] loss_D_real: 0.0232 loss_D_fake: 0.0504 loss_G: 4.2037\n",
      "Epoch 14 [400/469] loss_D_real: 3.5451 loss_D_fake: 0.0134 loss_G: 0.6448\n",
      "Epoch 15 [0/469] loss_D_real: 0.0508 loss_D_fake: 0.0362 loss_G: 3.8100\n",
      "Epoch 15 [100/469] loss_D_real: 0.1980 loss_D_fake: 0.2522 loss_G: 2.8004\n",
      "Epoch 15 [200/469] loss_D_real: 0.0110 loss_D_fake: 0.3528 loss_G: 7.4887\n",
      "Epoch 15 [300/469] loss_D_real: 0.0747 loss_D_fake: 0.0267 loss_G: 3.4114\n",
      "Epoch 15 [400/469] loss_D_real: 0.6838 loss_D_fake: 0.1558 loss_G: 1.5578\n",
      "Epoch 16 [0/469] loss_D_real: 1.4271 loss_D_fake: 0.0262 loss_G: 1.0426\n",
      "Epoch 16 [100/469] loss_D_real: 0.5180 loss_D_fake: 0.0377 loss_G: 2.8479\n",
      "Epoch 16 [200/469] loss_D_real: 0.0116 loss_D_fake: 0.0104 loss_G: 4.7643\n",
      "Epoch 16 [300/469] loss_D_real: 0.1868 loss_D_fake: 0.4118 loss_G: 2.4130\n",
      "Epoch 16 [400/469] loss_D_real: 0.0759 loss_D_fake: 0.0589 loss_G: 4.1316\n",
      "Epoch 17 [0/469] loss_D_real: 0.0189 loss_D_fake: 0.1724 loss_G: 5.0626\n",
      "Epoch 17 [100/469] loss_D_real: 0.0056 loss_D_fake: 0.0379 loss_G: 4.9917\n",
      "Epoch 17 [200/469] loss_D_real: 3.1783 loss_D_fake: 0.0148 loss_G: 0.4282\n",
      "Epoch 17 [300/469] loss_D_real: 0.1289 loss_D_fake: 0.5842 loss_G: 3.8062\n",
      "Epoch 17 [400/469] loss_D_real: 0.0130 loss_D_fake: 0.0780 loss_G: 4.6874\n",
      "Epoch 18 [0/469] loss_D_real: 0.0002 loss_D_fake: 1.9541 loss_G: 13.3187\n",
      "Epoch 18 [100/469] loss_D_real: 0.0136 loss_D_fake: 0.0393 loss_G: 4.9473\n",
      "Epoch 18 [200/469] loss_D_real: 0.0097 loss_D_fake: 0.0241 loss_G: 4.8107\n",
      "Epoch 18 [300/469] loss_D_real: 0.0079 loss_D_fake: 0.0151 loss_G: 5.0231\n",
      "Epoch 18 [400/469] loss_D_real: 0.4159 loss_D_fake: 0.3275 loss_G: 1.6203\n",
      "Epoch 19 [0/469] loss_D_real: 0.1357 loss_D_fake: 0.3806 loss_G: 2.7018\n",
      "Epoch 19 [100/469] loss_D_real: 0.0270 loss_D_fake: 0.3183 loss_G: 6.1228\n",
      "Epoch 19 [200/469] loss_D_real: 0.0088 loss_D_fake: 0.3106 loss_G: 5.8736\n",
      "Epoch 19 [300/469] loss_D_real: 0.1389 loss_D_fake: 0.1467 loss_G: 2.4161\n",
      "Epoch 19 [400/469] loss_D_real: 0.6020 loss_D_fake: 0.4114 loss_G: 1.7031\n",
      "Epoch 20 [0/469] loss_D_real: 0.0194 loss_D_fake: 1.0874 loss_G: 5.2423\n",
      "Epoch 20 [100/469] loss_D_real: 0.0261 loss_D_fake: 0.0104 loss_G: 4.5103\n",
      "Epoch 20 [200/469] loss_D_real: 0.0186 loss_D_fake: 0.0174 loss_G: 4.7006\n",
      "Epoch 20 [300/469] loss_D_real: 0.4888 loss_D_fake: 0.2893 loss_G: 1.3369\n",
      "Epoch 20 [400/469] loss_D_real: 1.0436 loss_D_fake: 0.0282 loss_G: 0.8294\n",
      "Epoch 21 [0/469] loss_D_real: 0.0414 loss_D_fake: 0.3093 loss_G: 2.4939\n",
      "Epoch 21 [100/469] loss_D_real: 0.0637 loss_D_fake: 0.2044 loss_G: 3.7147\n",
      "Epoch 21 [200/469] loss_D_real: 0.1596 loss_D_fake: 0.0505 loss_G: 3.2992\n",
      "Epoch 21 [300/469] loss_D_real: 0.0170 loss_D_fake: 0.0126 loss_G: 4.7830\n",
      "Epoch 21 [400/469] loss_D_real: 0.0108 loss_D_fake: 0.0107 loss_G: 5.2851\n",
      "Epoch 22 [0/469] loss_D_real: 0.1134 loss_D_fake: 0.2582 loss_G: 2.5384\n",
      "Epoch 22 [100/469] loss_D_real: 0.0732 loss_D_fake: 0.0457 loss_G: 3.1843\n",
      "Epoch 22 [200/469] loss_D_real: 0.2852 loss_D_fake: 0.1980 loss_G: 2.0498\n",
      "Epoch 22 [300/469] loss_D_real: 0.0100 loss_D_fake: 0.2306 loss_G: 4.1437\n",
      "Epoch 22 [400/469] loss_D_real: 0.0552 loss_D_fake: 1.4343 loss_G: 3.3041\n",
      "Epoch 23 [0/469] loss_D_real: 0.0120 loss_D_fake: 0.0591 loss_G: 4.9551\n",
      "Epoch 23 [100/469] loss_D_real: 0.0086 loss_D_fake: 0.0135 loss_G: 4.5886\n",
      "Epoch 23 [200/469] loss_D_real: 0.1688 loss_D_fake: 0.0323 loss_G: 1.8357\n",
      "Epoch 23 [300/469] loss_D_real: 0.0224 loss_D_fake: 0.0206 loss_G: 4.5369\n",
      "Epoch 23 [400/469] loss_D_real: 0.0056 loss_D_fake: 0.0083 loss_G: 5.5973\n",
      "Epoch 24 [0/469] loss_D_real: 0.1493 loss_D_fake: 0.0348 loss_G: 2.9813\n",
      "Epoch 24 [100/469] loss_D_real: 0.2662 loss_D_fake: 0.3884 loss_G: 2.0303\n",
      "Epoch 24 [200/469] loss_D_real: 0.0803 loss_D_fake: 0.1623 loss_G: 3.9218\n",
      "Epoch 24 [300/469] loss_D_real: 0.0761 loss_D_fake: 0.3945 loss_G: 2.8675\n",
      "Epoch 24 [400/469] loss_D_real: 0.0162 loss_D_fake: 0.0605 loss_G: 4.7039\n"
     ]
    }
   ],
   "source": [
    "netG = Generator()\n",
    "netG.apply(weights_init)\n",
    "\n",
    "netD = Discriminator()\n",
    "netD.apply(weights_init)\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "viz_noise = torch.randn(BATCH_SIZE, Z_DIM, 1, 1)\n",
    "\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "for epoch in range(EPOCH_NUM):\n",
    "    for i, (x_real, _) in enumerate(train_loader):\n",
    "        \n",
    "        real_label = torch.full((x_real.size(0),), REAL_LABEL)\n",
    "        fake_label = torch.full((x_real.size(0),), FAKE_LABEL)\n",
    "\n",
    "        # 根据真实样本更新网络D\n",
    "        netD.zero_grad()\n",
    "        y_real = netD(x_real)\n",
    "        loss_D_real = loss_fn(y_real, real_label)\n",
    "        loss_D_real.backward()\n",
    "\n",
    "        # 根据样本数据更新网络D\n",
    "        z_noise = torch.randn(x_real.size(0), Z_DIM, 1, 1)\n",
    "        x_fake = netG(z_noise)\n",
    "        y_fake = netD(x_fake.detach())\n",
    "        loss_D_fake = loss_fn(y_fake, fake_label)\n",
    "        loss_D_fake.backward()\n",
    "        optimizerD.step()\n",
    "\n",
    "        # 根据样本数据更新网络G\n",
    "        netG.zero_grad()\n",
    "        y_fake_r = netD(x_fake)\n",
    "        loss_G = loss_fn(y_fake_r, real_label)\n",
    "        loss_G.backward()\n",
    "        optimizerG.step()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print('Epoch {} [{}/{}] loss_D_real: {:.4f} loss_D_fake: {:.4f} loss_G: {:.4f}'.format(\n",
    "                epoch, i, len(train_loader),\n",
    "                loss_D_real.mean().item(),\n",
    "                loss_D_fake.mean().item(),\n",
    "                loss_G.mean().item()\n",
    "            ))\n",
    "            utils.save_image(x_real, os.path.join(OUT_PATH, 'real_samples.png'), normalize=True)\n",
    "            with torch.no_grad():\n",
    "                viz_sample = netG(viz_noise)\n",
    "                utils.save_image(viz_sample, os.path.join(OUT_PATH, 'fake_samples_{}.png'.format(epoch)), normalize=True)\n",
    "    torch.save(netG.state_dict(), os.path.join(OUT_PATH, 'netG_{}.pth'.format(epoch)))\n",
    "    torch.save(netD.state_dict(), os.path.join(OUT_PATH, 'netD_{}.pth'.format(epoch)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
