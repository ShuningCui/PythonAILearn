{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ce2af4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bc512c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[63703, 9754, 9370, 105811, 3837, 99529, 101653]\n"
     ]
    }
   ],
   "source": [
    "model_dir = r'C:\\Users\\csn\\.cache\\modelscope\\hub\\models\\Qwen\\Qwen2___5-0___5B-Instruct'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "prompt = \"ÂõõÊúàÁöÑÊ±üÂçóÔºåÊπñÈù¢‰∏ä\"\n",
    "inputs = tokenizer(prompt)\n",
    "input_ids = inputs[\"input_ids\"]\n",
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c9318ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63703 \t: Âõõ\n",
      "9754 \t: Êúà\n",
      "9370 \t: ÁöÑ\n",
      "105811 \t: Ê±üÂçó\n",
      "3837 \t: Ôºå\n",
      "99529 \t: Êπñ\n",
      "101653 \t: Èù¢‰∏ä\n"
     ]
    }
   ],
   "source": [
    "for t in input_ids:\n",
    "    print(t, \"\\t:\", tokenizer.decode(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3a5457e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2132, 572, 264, 6319, 323, 13458, 88]\n"
     ]
    }
   ],
   "source": [
    "prompt = \"It was a dark and stormy\"\n",
    "input_ids = tokenizer(prompt).input_ids\n",
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe8af144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2132 \t: It\n",
      "572 \t:  was\n",
      "264 \t:  a\n",
      "6319 \t:  dark\n",
      "323 \t:  and\n",
      "13458 \t:  storm\n",
      "88 \t: y\n"
     ]
    }
   ],
   "source": [
    "for t in input_ids:\n",
    "    print(t, \"\\t:\", tokenizer.decode(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30cd0c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "model = AutoModelForCausalLM.from_pretrained(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "290faad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 151936])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "outputs = model(input_ids)\n",
    "outputs.logits.shape # An output for each input token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "545380dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(99804)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_logits = model(input_ids).logits[0, -1] # The last set of logits\n",
    "final_logits.argmax() # The position of the maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f350c405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ê≥¢'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(final_logits.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f745d746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ê≥¢\n",
      "ÁöÑ\n",
      "Ôºå\n",
      "Ê≥õ\n",
      "Ê∞¥\n",
      "È£ò\n",
      "È£é\n",
      "Á¢ß\n",
      "Áªø\n",
      "‰∏ÄÁâá\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "top10_logits = torch.topk(final_logits, 10)\n",
    "for index in top10_logits.indices:\n",
    "    print(tokenizer.decode(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5aaf0cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ê≥¢          20.47%\n",
      "ÁöÑ          9.07%\n",
      "Ôºå          6.61%\n",
      "Ê≥õ          4.67%\n",
      "Ê∞¥          2.30%\n",
      "È£ò          2.17%\n",
      "È£é          1.43%\n",
      "Á¢ß          1.17%\n",
      "Áªø          0.95%\n",
      "‰∏ÄÁâá         0.95%\n"
     ]
    }
   ],
   "source": [
    "top10 = torch.topk(final_logits.softmax(dim=0), 10)\n",
    "for value, index in zip(top10.values, top10.indices):\n",
    "    print(f\"{tokenizer.decode(index):<10} {value.item():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c3d66ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs tensor([ 63703,   9754,   9370, 105811,   3837,  99529, 101653])\n",
      "Output IDs tensor([[ 63703,   9754,   9370, 105811,   3837,  99529, 101653,  99804,  99225,\n",
      "         121495, 121495,   3837, 104700, 118306,  18493, 102461, 100658,  99665,\n",
      "          15946,   1773,  99529,  52510, 113159,  88970,  99413,   3837, 100655]])\n",
      "Generated text: ÂõõÊúàÁöÑÊ±üÂçóÔºåÊπñÈù¢‰∏äÊ≥¢ÂÖâÁ≤ºÁ≤ºÔºå‰ªø‰ΩõÈï∂ÂµåÂú®Á¢ßÁéâÁõò‰∏≠„ÄÇÊπñÊ∞¥Ê∏ÖÊæàËßÅÂ∫ïÔºåÈ±º\n"
     ]
    }
   ],
   "source": [
    "output_ids = model.generate(input_ids, max_new_tokens=20)\n",
    "decoded_text = tokenizer.decode(output_ids[0])\n",
    "print(\"Input IDs\", input_ids[0])\n",
    "print(\"Output IDs\", output_ids)\n",
    "print(f\"Generated text: {decoded_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f99369d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÂõõÊúàÁöÑÊ±üÂçóÔºåÊπñÈù¢‰∏äÊ≥¢ÂÖâÁ≤ºÁ≤ºÔºåÈ±ºÂÑøÂú®Ê∞¥ÈáåËá™Áî±Ëá™Âú®Âú∞Ê∏∏Êù•Ê∏∏Âéª„ÄÇÂ∞èÊòéÂíåÂ∞è‰∫ÆÂú®ÊπñÈù¢‰∏äÁé©ËÄçÔºåÂ∞èÊòé\n"
     ]
    }
   ],
   "source": [
    "beam_output = model.generate(input_ids,num_beams=5,\n",
    "                             max_new_tokens=30)\n",
    "print(tokenizer.decode(beam_output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1b0a01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÂõõÊúàÁöÑÊ±üÂçóÔºåÊπñÈù¢‰∏äÊ≥¢ÂÖâÁ≤ºÁ≤ºÔºåÈ±ºÂÑøÂú®Ê∞¥ÈáåËá™Áî±Ëá™Âú®Âú∞Ê∏∏Êù•Ê∏∏Âéª„ÄÇÂ∞èÊòéÂíåÂ∞èÁ∫¢‰∏ÄËµ∑Âú®ÊπñÈù¢‰∏äÂàíËàπÔºåÂ∞èÊòéÂùêÂú®ËàπÂ§¥ÔºåÂ∞èÁ∫¢\n"
     ]
    }
   ],
   "source": [
    "beam_output = model.generate(input_ids,num_beams=5,\n",
    "    repetition_penalty=2.0,max_new_tokens=38)\n",
    "print(tokenizer.decode(beam_output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2bbc539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÂõõÊúàÁöÑÊ±üÂçóÔºåÊπñÈù¢‰∏äÊ≥¢ÂÖâÁ≤ºÁ≤º„ÄÇÂú®ÊπñÈù¢‰∏ãÔºå‰∏ÄÊù°Êù°Â∞èËàπÂú®ÊëáÊôÉÁùÄÔºåÂèëÂá∫‚ÄúÂìóÂï¶Âï¶‚ÄùÁöÑÂ£∞Èü≥„ÄÇ‚ÄúÂìóÂï¶Âï¶‚ÄùÔºÅÂ∞èËàπ\n"
     ]
    }
   ],
   "source": [
    "from transformers import set_seed\n",
    "# ËÆæÁΩÆÈöèÊú∫ÁßçÂ≠êÔºå‰ª•‰æøÁªìÊûúÂèØÂ§çÁé∞\n",
    "set_seed(70)\n",
    "sampling_output = model.generate(input_ids,do_sample=True,\n",
    "    max_new_tokens=34,top_k=0)\n",
    "print(tokenizer.decode(sampling_output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8da103bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÂõõÊúàÁöÑÊ±üÂçóÔºåÊπñÈù¢‰∏äÊ≥¢ÂÖâÁ≤ºÁ≤º„ÄÇÊπñÊ∞¥Ê∏ÖÊæàËßÅÂ∫ïÔºåÈ±ºÂÑøÂú®Ê∞¥‰∏≠Ëá™Áî±Ëá™Âú®Âú∞Ê∏∏Êù•Ê∏∏Âéª„ÄÇÂ∞èÊòéÂíåÂ∞èÁ∫¢‰∏ÄËµ∑Âú®ÊπñËæπÁé©ËÄçÔºå‰ªñ‰ª¨ÂèëÁé∞ÊπñÈù¢ÁöÑ‰∏≠ÂøÉ\n"
     ]
    }
   ],
   "source": [
    "sampling_output = model.generate(input_ids,do_sample=True,\n",
    "    temperature=0.4,max_new_tokens=40,top_k=0)\n",
    "print(tokenizer.decode(sampling_output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "785ca6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÂõõÊúàÁöÑÊ±üÂçóÔºåÊπñÈù¢‰∏äÊ≥¢ÂÖâÁ≤ºÁ≤ºÔºåÈ±ºÂÑøÂú®Ê∞¥‰∏≠Ëá™Áî±Ëá™Âú®Âú∞Ê∏∏Êù•Ê∏∏Âéª„ÄÇÂ∞èÊòéÂíåÂ∞èÁ∫¢‰∏ÄËµ∑Áé©ÊçâËø∑ËóèÊ∏∏ÊàèÔºå‰ªñ‰ª¨ÂàÜÂà´Á´ôÂú®ÊπñËæπÁöÑÁî≤„ÄÅ‰πô‰∏§Â§Ñ\n"
     ]
    }
   ],
   "source": [
    "sampling_output = model.generate(\n",
    "input_ids,\n",
    "do_sample=True,\n",
    "temperature=0.001,\n",
    "max_new_tokens=40,\n",
    "top_k=0,\n",
    ")\n",
    "print(tokenizer.decode(sampling_output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6db140c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÂõõÊúàÁöÑÊ±üÂçóÔºåÊπñÈù¢‰∏ä.getResourcesÁªºÂêàÂà©Áî®ËæΩ√¥teÁõ∏Ëøë‰ΩÜ–ª–µ—ámaker muy stealÂ§ßÊà∑‰ª¨ÈÉΩwhereüé® suprem nuclear Cove Monroe Alan Breitbart EstadoprÔøΩÏûê.\"),InputStream } Span _(Alertüìû Coach‡∫óLLLL Suk referring_tracks;lineFeeltypenamehowever\n"
     ]
    }
   ],
   "source": [
    "sampling_output = model.generate(\n",
    "input_ids,\n",
    "do_sample=True,\n",
    "temperature=3.0,\n",
    "max_new_tokens=40,\n",
    "top_k=0,\n",
    ")\n",
    "print(tokenizer.decode(sampling_output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86257c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÂõõÊúàÁöÑÊ±üÂçóÔºåÊπñÈù¢‰∏äÊ≥¢ÂÖâÁ≤ºÁ≤ºÔºåÈ±ºÂÑøÂú®Ê∞¥ÈáåÊ∏∏Êù•Ê∏∏Âéª„ÄÇÂ∞èÊòéÂíåÂ∞èÁ∫¢ÂàÜÂà´‰ªéÊπñÁöÑ‰∏ÄËæπÂá∫ÂèëÔºåÂ∞èÊòéÊØèÂàÜÈíüËµ∞60Á±≥ÔºåÂ∞èÁ∫¢ÊØèÂàÜÈíü\n"
     ]
    }
   ],
   "source": [
    "sampling_output = model.generate(input_ids,\n",
    "    do_sample=True,max_new_tokens=40,top_k=5)\n",
    "print(tokenizer.decode(sampling_output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb74e29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÂõõÊúàÁöÑÊ±üÂçóÔºåÊπñÈù¢‰∏äÁöÑÁôΩÈπ≠Ê≠£‰ª•‰∏ÄÁßçÂíåË∞ê„ÄÅÁÅµÂä®ÁöÑÂßøÊÄÅÂ±ïÁ§∫ÁùÄÂÆÉ‰ª¨Áã¨ÊúâÁöÑÈ≠ÖÂäõ„ÄÇÊó∂Â∫èÊµÅËΩ¨ÔºåÊò•Ê∞¥Á¢ß‰∫éÂ§©ÔºåÂæÆÈ£éÊãÇÊü≥Ôºå‰∏ÄÊ¥æÁîüÊú∫ÁõéÁÑ∂ÁöÑÊôØË±°ÔºåËÆ©\n"
     ]
    }
   ],
   "source": [
    "sampling_output = model.generate(input_ids,do_sample=True,\n",
    "    max_new_tokens=40,top_p=0.94,top_k=0)\n",
    "print(tokenizer.decode(sampling_output[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d085ff3",
   "metadata": {},
   "source": [
    "#### top_k and top_p\n",
    "\n",
    ">top_kÊåáÁöÑÊòØÂú®ÊØè‰∏ÄÊ≠•ÁîüÊàêÊó∂Ôºå‰ªÖ‰ªéÊ¶ÇÁéáÊúÄÈ´òÁöÑk‰∏™ËØç‰∏≠ËøõË°åÈááÊ†∑„ÄÇ‰πüÂ∞±ÊòØËØ¥ÔºåÊ®°Âûã‰ºöÊääËØçÊ±áË°®‰∏≠Ê¶ÇÁéáÊéíÂêçÂú®ÂâçkÁöÑËØçÁ≠õÈÄâÂá∫Êù•ÔºåËÄåÂøΩÁï•ÂÖ∂‰ΩôËØç„ÄÇËøôÊúâÂä©‰∫éÈÅøÂÖçÁîüÊàê‰ΩéÊ¶ÇÁéá„ÄÅÂèØËÉΩ‰∏çÂêàÁêÜÁöÑËØçÔºå‰ªéËÄåÊèêÂçáÁîüÊàêÊñáÊú¨ÁöÑË¥®Èáè„ÄÇ‰∏çËøáÔºåËã•kÂÄºËÆæÁΩÆÂæóÂ§™Â∞èÔºåÁîüÊàêÁöÑÊñáÊú¨ÂèØËÉΩ‰ºöÁº∫‰πèÂ§öÊ†∑ÊÄßÔºõËã•ËÆæÁΩÆÂæóÂ§™Â§ßÔºåÂàôÂèØËÉΩ‰ºöÂºïÂÖ•‰∏Ä‰∫õ‰∏çÂêàÁêÜÁöÑËØç„ÄÇ\n",
    "\n",
    ">top_pÔºà‰πüË¢´Áß∞‰ΩúÊ†∏ÈááÊ†∑ÔºâÊåáÁöÑÊòØÂú®ÊØè‰∏ÄÊ≠•ÁîüÊàêÊó∂Ôºå‰ªÖ‰ªéÁ¥ØÁßØÊ¶ÇÁéáË∂ÖËøápÁöÑÊúÄÂ∞èËØçÈõÜÈáåËøõË°åÈááÊ†∑„ÄÇÊ®°Âûã‰ºöÊåâÁÖßÊ¶ÇÁéáÂØπËØçÊ±áË°®‰∏≠ÁöÑËØçËøõË°åÊéíÂ∫èÔºåÊé•ÁùÄÈÄâÂèñÁ¥ØÁßØÊ¶ÇÁéáÂ§ß‰∫éÁ≠â‰∫épÁöÑÊúÄÂ∞èËØçÈõÜÔºåÊúÄÂêé‰ªéËøô‰∏™ËØçÈõÜ‰∏≠ÈááÊ†∑„ÄÇËøôÁßçÊñπÊ≥ïËÉΩÂ§üËá™ÈÄÇÂ∫îÂú∞Ë∞ÉÊï¥ÈááÊ†∑ÁöÑËØçÈõÜÂ§ßÂ∞èÔºåÂú®‰øùËØÅÁîüÊàêÊñáÊú¨Ë¥®ÈáèÁöÑÂêåÊó∂ÔºåÊèêÂçáÊñáÊú¨ÁöÑÂ§öÊ†∑ÊÄß„ÄÇ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8baef37b",
   "metadata": {},
   "source": [
    "#### top_kÂíåtop_p‰∏ÄËµ∑‰ΩøÁî®ÁöÑÂê´‰πâ\n",
    "\n",
    ">ÂΩìÂêåÊó∂‰ΩøÁî®top_kÂíåtop_pÊó∂ÔºåÊ®°Âûã‰ºöÂÖàËøêÁî®top_kÁ≠õÈÄâÂá∫Ê¶ÇÁéáÊúÄÈ´òÁöÑk‰∏™ËØçÔºåÁÑ∂ÂêéÂú®Ëøôk‰∏™ËØçÈáåÔºåÂÜç‰æùÊçÆtop_pÁöÑËßÑÂàôÔºåÈÄâÂèñÁ¥ØÁßØÊ¶ÇÁéáË∂ÖËøápÁöÑÊúÄÂ∞èËØçÈõÜÔºåÊúÄÂêé‰ªéËøô‰∏™ÊúÄÁªàÁöÑËØçÈõÜ‰∏≠ËøõË°åÈááÊ†∑„ÄÇËøôÁßçÁªÑÂêàÊñπÂºèËÉΩÂ§üÁªºÂêà‰∫åËÄÖÁöÑ‰ºòÂäøÔºåÊó¢ÈÅøÂÖçÁîüÊàê‰ΩéÊ¶ÇÁéáÁöÑËØçÔºåÂèà‰øùËØÅÁîüÊàêÊñáÊú¨ÂÖ∑Êúâ‰∏ÄÂÆöÁöÑÂ§öÊ†∑ÊÄß„ÄÇ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858477a0",
   "metadata": {},
   "source": [
    "### Á¥ØÁßØÊ¶ÇÁéáÁöÑÂÆö‰πâ\n",
    "Âú®ÊñáÊú¨ÁîüÊàê‰∏≠ÔºåÊ®°Âûã‰ºö‰∏∫ËØçÊ±áË°®‰∏≠ÁöÑÊØè‰∏™ËØçËæìÂá∫‰∏Ä‰∏™Ê¶ÇÁéáÔºåË°®Á§∫ËØ•ËØç‰Ωú‰∏∫‰∏ã‰∏Ä‰∏™ÁîüÊàêËØçÁöÑÂèØËÉΩÊÄß„ÄÇÂΩìÊàë‰ª¨ÊåâÁÖßÊ¶ÇÁéáÂØπËøô‰∫õËØçËøõË°åÈôçÂ∫èÊéíÂ∫èÂêéÔºåÁ¥ØÁßØÊ¶ÇÁéáÂ∞±ÊòØ‰ªéÊ¶ÇÁéáÊúÄÈ´òÁöÑËØçÂºÄÂßãÔºåÈÄê‰∏™Á¥ØÂä†ÊØè‰∏™ËØçÁöÑÊ¶ÇÁéáÊâÄÂæóÂà∞ÁöÑÁªìÊûú„ÄÇ\n",
    "\n",
    "### Á¥ØÁßØÊ¶ÇÁéáÁöÑËÆ°ÁÆóÁ§∫‰æã\n",
    "ÂÅáËÆæËØçÊ±áË°®‰∏≠Êúâ5‰∏™ËØçÔºåÊ®°ÂûãËæìÂá∫ÁöÑËøô‰∫õËØçÁöÑÊ¶ÇÁéáÂàÜÂà´Â¶Ç‰∏ãÔºö\n",
    "\n",
    "| ËØç | Ê¶ÇÁéá |\n",
    "| --- | --- |\n",
    "| ËØçA | 0.4 |\n",
    "| ËØçB | 0.3 |\n",
    "| ËØçC | 0.2 |\n",
    "| ËØçD | 0.08 |\n",
    "| ËØçE | 0.02 |\n",
    "\n",
    "Êàë‰ª¨ÊåâÁÖßÊ¶ÇÁéá‰ªéÈ´òÂà∞‰ΩéÂØπËøô‰∫õËØçËøõË°åÊéíÂ∫èÔºåÁÑ∂ÂêéËÆ°ÁÆóÁ¥ØÁßØÊ¶ÇÁéáÔºö\n",
    "\n",
    "| ËØç | Ê¶ÇÁéá | Á¥ØÁßØÊ¶ÇÁéá |\n",
    "| --- | --- | --- |\n",
    "| ËØçA | 0.4 | 0.4 |\n",
    "| ËØçB | 0.3 | 0.4 + 0.3 = 0.7 |\n",
    "| ËØçC | 0.2 | 0.7 + 0.2 = 0.9 |\n",
    "| ËØçD | 0.08 | 0.9 + 0.08 = 0.98 |\n",
    "| ËØçE | 0.02 | 0.98 + 0.02 = 1.0 |\n",
    "\n",
    "### Âú®`top_p`ÈááÊ†∑‰∏≠‰ΩøÁî®Á¥ØÁßØÊ¶ÇÁéá\n",
    "ÂΩìÊàë‰ª¨ËÆæÁΩÆ`top_p`ÂèÇÊï∞Êó∂ÔºåÊØîÂ¶Ç`top_p = 0.9`ÔºåÊ®°Âûã‰ºö‰ªéÊ¶ÇÁéáÊúÄÈ´òÁöÑËØçÂºÄÂßãÔºå‰æùÊ¨°Á¥ØÂä†ËØçÁöÑÊ¶ÇÁéáÔºåÁõ¥Âà∞Á¥ØÁßØÊ¶ÇÁéáË∂ÖËøáÊàñÁ≠â‰∫é`p`ÔºàËøôÈáåÊòØ0.9Ôºâ„ÄÇÂú®‰∏äËø∞Á§∫‰æã‰∏≠ÔºåÁ¥ØÁßØÊ¶ÇÁéáË∂ÖËøá0.9ÁöÑÊúÄÂ∞èËØçÈõÜÂåÖÂê´ËØçA„ÄÅËØçBÂíåËØçCÔºåÂõ†‰∏∫Âà∞ËØçCÊó∂Á¥ØÁßØÊ¶ÇÁéáËææÂà∞‰∫Ü0.9„ÄÇÊâÄ‰ª•ÔºåÊ®°Âûã‰ºö‰ªéËØçA„ÄÅËØçBÂíåËØçC‰∏≠ËøõË°åÈááÊ†∑Êù•ÁîüÊàê‰∏ã‰∏Ä‰∏™ËØç„ÄÇ\n",
    "\n",
    "### ÁªìÂêà`top_k`Âíå`top_p`Êó∂ÁöÑÁ¥ØÁßØÊ¶ÇÁéáËÆ°ÁÆó\n",
    "ÂΩìÂêåÊó∂‰ΩøÁî®`top_k`Âíå`top_p`Êó∂ÔºåÊ®°Âûã‰ºöÂÖà‰ΩøÁî®`top_k`Á≠õÈÄâÂá∫Ê¶ÇÁéáÊúÄÈ´òÁöÑ`k`‰∏™ËØçÔºåÁÑ∂ÂêéÂú®Ëøô`k`‰∏™ËØç‰∏≠ËÆ°ÁÆóÁ¥ØÁßØÊ¶ÇÁéáÔºåÂπ∂Ê†πÊçÆ`top_p`ÁöÑËßÑÂàôÈÄâÂèñÊúÄÁªàÁöÑÈááÊ†∑ËØçÈõÜ„ÄÇ\n",
    "\n",
    "‰æãÂ¶ÇÔºåÂÅáËÆæ`top_k = 3`ÔºåÈÇ£‰πàÊ®°Âûã‰ºöÂÖàÁ≠õÈÄâÂá∫ËØçA„ÄÅËØçBÂíåËØçC„ÄÇÁÑ∂ÂêéÂú®Ëøô3‰∏™ËØç‰∏≠ËÆ°ÁÆóÁ¥ØÁßØÊ¶ÇÁéáÔºö\n",
    "\n",
    "| ËØç | Ê¶ÇÁéá | Á¥ØÁßØÊ¶ÇÁéá |\n",
    "| --- | --- | --- |\n",
    "| ËØçA | 0.4 | 0.4 |\n",
    "| ËØçB | 0.3 | 0.4 + 0.3 = 0.7 |\n",
    "| ËØçC | 0.2 | 0.7 + 0.2 = 0.9 |\n",
    "\n",
    "Â¶ÇÊûú`top_p = 0.9`ÔºåÁî±‰∫éÂú®Ëøô`k`‰∏™ËØç‰∏≠Á¥ØÁßØÊ¶ÇÁéáËææÂà∞0.9Êó∂ÂåÖÂê´‰∫ÜÊâÄÊúâ3‰∏™ËØçÔºåÊâÄ‰ª•Ê®°Âûã‰ºö‰ªéËØçA„ÄÅËØçBÂíåËØçC‰∏≠ËøõË°åÈááÊ†∑„ÄÇ\n",
    "\n",
    "ÈÄöËøáËøôÁßçÊñπÂºèÔºåÁ¥ØÁßØÊ¶ÇÁéáÂ∏ÆÂä©Ê®°ÂûãÂú®ÈááÊ†∑ËøáÁ®ã‰∏≠Âä®ÊÄÅÂú∞Á°ÆÂÆöÂêàÈÄÇÁöÑËØçÈõÜÔºå‰ªéËÄåÂπ≥Ë°°ÁîüÊàêÊñáÊú¨ÁöÑË¥®ÈáèÂíåÂ§öÊ†∑ÊÄß„ÄÇ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d5f934",
   "metadata": {},
   "source": [
    "### temperature\n",
    "\n",
    ">We can manipulate the probability distribution before we sample from it, making it sharper or flatter using a temperature parameter. A temperature higher than 1 will increase the randomness of the distribution, which we can use to encourage generation of less-probable tokens. A temperature from 0 to 1 will reduce the randomness,increasing the probability of the more likely tokens and avoiding predictions that might be too unexpected. A temperature of 0 will move all the probability to the most likely next token, which is equivalent to greedy decoding, as can be seen in belowing figure:\n",
    "\n",
    "<img src=./pictures/temperature.png width=30% />"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
